 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe isabela albuquerque probabilistic graphical models goal model multivariate data graph probability theory more illustratively probability statistics probabilistic model answers queries sampling data probability statistics inverse problem lecture september fall applications some illustrative examples hidden markov models applications notation observed random variable represented graphical model shaded node observed random variable represented graphical model empty node graph edges represents possible correlations between random variables graphical models lack edges graph will represent conditional independence assumptions will later important when modeling problem using graphical models random variables represent quantities interest context random vector often just called random variable thus random variable might scalar vector valued example speech recognition sound wave encoding small time window spectral decomposition phoneme xtxt example part speech tagging word part speech word grammatical classification verb this lecture september fall example gene finding sequence nitrogenous base coding coding example control system latent state observation where continuous vectors given control term terms represent noise system they modeled gaussian noise this kalman filter graphical models back part speech tagging example notation observation words represented vocabulary size problem want model which corresponds exponential size state space thus parameters have estimated define probability distribution trick make factorization assumption about distribution each factor seen clique graphical model needs parameters specified have factors this factorization reduce total number parameters from exponentially grows with linearly grows with lecture september fall back problem want compute marginal probability using factorization assumption write applying distributive property product over rewrite equation this organized efficient compute marginal known message passing algorithm term named message denoted following figure illustrates represented arrow passing through graph themes representation represent structured probability distributions related parameterization full table exponential family estimation given data samples learn parameters distribution underlying observations related learning maximum likelihood estimation inference answer questions about data computing conditional distributions marginals efficient computation message passing algorithm 
 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe william chelle disclaimer these notes have only been lightly proofread probability review motivation question probability data science answer probability theory principled framework model uncertainty question where does uncertainty come from answer there several sources intrinsic certain phenomenon quantum mechanics reasoning about future events only partial information about some complex phenomenon throwing dice hard fully observe initial conditions object recognition model mapping from pixels objects incredibly complex notation note that probability theorists graphical models community both notational shorthands meaning notations often inferred from context therefore recall standard notations random variables will noted sometimes usually they will real valued will denote realizations former random variables values take lecture september fall formally define sample space elementary events then random variable measurable mapping then probability distribution mapping where subsets events field such that measurements world possibilities kolmogorov axioms when disjoint therefore probability distribution induces probability distribution image event thus gets probability shorthand actually used shorthand even more ambiguous where example case dice roll consider random variables measures whether dice result even measures whether dice result formally where otherwise indicator function temporarily assumed countable wikipedia field formalism necessary when uncountable which happens soon consider continuous random variable image possible outputs lecture september fall define joint distribution called random vector vector valued random variable with random variable meant generalized sense represent joint distribution table such running example instance also define context joint distribution marginal distribution distribution components random vector rule this rule property deriving from axioms left exercice reader types random variables discrete random variables discrete random variable countable probability distribution fully defined probability mass function this notation shortened even typing only denoting values variable thereby possible that even sense that means means more generally probability distribution fully characterized cumulative distribution function this comma means intersection both events lecture september fall following properties decreasing example cumulative distribution function discrete random variables cumulative distribution function piecewise constant jumps continuous random variables continuous random variable cumulative distribution function absolutely tinuous differentiable almost everywhere said called probability density function random variable where continuous probability density function continuous analog probability mass function discrete random variable with sums becoming integrals hence discrete continuous prob mass function prob density function note continuous case density function greater than sufficiently narrow interval instance uniform distribution otherwise other random variable basics expectation mean expectation random variable continuous case variance variance measure dispersion values around mean lecture september fall independance independant from noted random variables mutually independant conditioning events suppose that define probability given terms sample space that means look subspace where happens that space look subspace where also happens random variables thus normalization constant necessary order real probability distribution definition product rule product rule always true with subtle point that undefined bayes rule bayes rule about inverting conditioning variables bayes rule chain rule successive application product rule always true that chain rule last part simplified using conditional independance asumptions make like case directed graphical models probability theory usually care what happens sets with probability zero free define value want when lecture september fall conditional independance conditionally independant given noted instance with probability that mother carries genetic disease chromosome probability first child carry disease same probability second child that independant given because only status mother impacts directly each child once that known children probabilities carrying disease independant from each other exercise reader prove that when 
 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe philippe brouillard tristan deleu disclaimer these notes have only been lightly proofread parametric models family distributions parametric model family distributions that defined fixed finite number parameters family distributions formally defined follows where possible understood from context depending parameter valid parameters support distribution usually fixed example support distribution modelling coin flip could similarly gamma distribution support notation indicate that random variable distributed known distribution symbol example indicate that random variable distributed bernoulli distribution parameter would write bern this notation shorthand bern where represents bern indicates that refer bernouilli distribution will later class parametric models which basically means that number parameters potentially infinite these models usually from data with number effective parameters growing with size training data using instead would abuse notation since only scalar specific lecture september fall take another example random variable distributed normal distribution with parameters would write that similar that continuous bernoulli distribution bernoulli random variable given follows support distribution space parameters from that expected value variance bernoulli random variable from figure below that variance highest point when intuitively bernoulli distribution models situation where there only possible outcomes either success failure classical example coin flip getting head success will equals this case parameter would probability head binomial distribution binomial distribution defined independent identically distributed bernoulli random variables with parameter formally note that instead also often used parameter bernoulli binomial distribution lecture september fall bern then have that support distribution space parameters given follows term equal number ways successes trials formally this defined follow term notice that product bernoulli random variables since bern expected value variance binomial random variable deduced from bernoulli expected value variance since indep intuitively binomial distribution seen model independent coin flips other distributions poisson distribution often used model count data poisson where mean parameter gaussian distribution most common distribution real numbers denoted where mean variance parameters here implicitly refers lecture september fall gamma distribution often used model positive numbers denoted gamma where shape parameter rate parameter here list other common distributions look them wikipedia laplace cauchy exponential beta dirichlet statistical concepts probability theory used infer generate data from model this well defined problem contrary statistics infer model based observed data this inverse problem that unfortunately defined probability theory model data statistics illustrate difference between probability statistics suppose have model that generate independent coin flips classical probability theory problem would calculate probability heads happening this case model would given without data case statistics would only have observed data heads trials model wouldn accessible classical statistics problem would infer parameters model that explains observed data what bias coin flip this example frequentist bayesian stated earlier statistics problem defined furthermore even meaning probability differ from different philosophical point views major schools thought using different meaning probability have arisen frequentist bayesian traditional frequentist semantic following represents limiting relative frequency observing could repeat infinite number experiments bayesian semantic following encodes agent belief that lecture september fall laws probability characterize rational combine beliefs evidence observations this approach many motivations terms gambling utility decision theory frequentist interpretation probability illustrate view frequentist interpretation will analyze example discrete random variable suppose that then bern which encodes event that takes value suppose repeat experiments large number times bern large numbers have that empirical average will converge expected value also show that empirical average will concentrates tightly around value central limit theorem consider which represents distribution expected value variance average following thus that variance empirical average goes zero showing concentration more precisely have central limit theorem that notice scaling difference large distribution empirical average close gaussian distribution with mean variance bayesian approach bayesian approach very simple philosophically treats uncertain quantities random variables lecture september fall fact encodes knowledge about system beliefs prior probabilistic models then uses laws probabilities bayes rule answers simplest example illustrate bayesian approach result coin flips biased coin believe that since unknown model random variable thus need prior distribution with sample space defined suppose observe result flips then update belief about using bayes rule where posterior belief likelihood observation model prior belief normalization marginal likelihood illustrate bayesian approach suppose that uniform prior doesn encode specific preferences where symbol means that proportional drop term that doesn contain scaling factor beta function defined gamma function defined note that then joint will mixed distribution lecture september fall beta beta distribution defined beta bayesian posterior distribution contains information need predict likelihood event example what probability that next coin flip using marginalization over using chain rule have definition model thus where conditional expectation called posterior mean meaningful bayesian estimator bayes since beta expected value beta beta then bayes estimator bayes compare estimator from frequentist approach that while unbiased bayesian estimator biased asymptotically unbiased furthermore bayesian estimator encodes uncertainty even data contains only head flips estimator gives small probability flip tail this however case with estimator which tends overfit convention lowercase used even random variable because already used parameter space notation statistical estimator based observations value included valid parameters frequentist statistics consider multiple possible estimators bayesian posterior mean moment matching after selecting estimator analyze their statistical properties bias variance consistency 
 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe philippe brouillard tristan deleu maximum likelihood principle given parametric family define likelihood function some observation denoted depending nature corresponding random variable here either probability mass function discrete probability density function continuous likelihood function parameter with observation fixed want find estimate best value parameter that explains observation this estimate called maximum likelihood estimator given argmax this means value parameter that maximizes probability observation function usually though only given single observation samples some distribution with that case likelihood function example binomial model consider family binomial distributions with parameters with given some observation random variable want estimate parameter that best explains this observation with maximum likelihood principle recall that binomial distribution goal maximize likelihood function even though highly linear function make things easier instead maximizing likelihood function directly maximize strictly increasing function lecture september fall since strictly increasing function common choice maximize likelihood function this leads same value argmax argmax using likelihood function could problematic when some parameter that case assigning this value effect maximization later here binomial model have constant that know form maximize first search stationary points likelihood that values such that this necessary condition maximum section stationary points likelihood given likelihood function binomial model also strictly concave thus being stationary point also sufficient condition global maximum section binomial model relative frequency observation which follows intuition furthermore even though general property this estimator unbiased note that maximized without specifying constraint even though required that however here this extra condition little effect optimization since stationary point already interior parameter space latter cases exploit monotonicity conclude that maxima boundaries resp lecture september fall comments optimization general being stationary point necessary condition local maximum when interior parameter space however sufficient stationary point either local maximum local minimum saddle point multivariate case also need check second derivative local maximum flocal maximum stationarypoints previous point only gives local result guarantee that global maximum need know global properties about function example function concave negative convex function then sufficient condition global maximum need careful though with cases where maximum boundary parameter space boundary that case necessarily stationary point meaning that zero similar multivariate case general necessary condition local maximum belongs interior local maximum need check hessian matrix negative definite this multivariate equivalent hessian where hessian also similar results multivariate case know global properties function example function concave then also sufficient condition global maximum verify that multivariate function concave have check hessian matrix negative semi definite whole parameter space multivariate equivalent hessian concave lecture september fall properties does always exist example estimate boundary parameter space boundary open necessarily unique likelihood function could have multiple maxima admissible general example multinomial model suppose that discrete random variable over choices could choose domain this random variable instead convenient encode random vector taking values unit bases this encoding called encoding widely used neural networks literature where coordinate this discrete random vector define family probability distributions with parameter parameter space called probability simplex choices given probability simplex dimensional object because constraint example here dimensional this makes optimization over parameter space more difficult distribution random vector called multinoulli distribution with parameter denoted mult where component multinoulli distribution seen equivalent bernoulli distribution over choices instead consider multinoulli random vectors mult then define random vector mult with distribution called multinomial distribution with parameters analogue binomial distribution over choices similar multinoulli bernoulli given lecture september fall some observation want estimate parameter that best explains this observation with maximum likelihood principle likelihood function where normalization constant where number times observe value note that remains function observation although this explicit dependence omitted here equivalently could have looked multinoulli model with parameter with observations instead multinomial model with single observation only effect here would lack normalization constant likelihood function like section take likelihood function make optimization simpler constant want maximize such that still valid element given constraints induced probability simplex this involves solving following constrained optimization problem subject solve this optimization problem have options could reparametrize with with constraint likelihood function maximize would become advantage here would that parameter space would full dimensional object sometimes called corner cube which more suitable setup optimization particular could apply techniques from section lecture september fall dimensional optimize here full dimensional choose lagrange multipliers approach lagrange multipliers method used solve constrained optimization problems with equality constraints more generally with inequality constraints well form here apply optimization problem maximization under equality constraint fundamental part lagrange multipliers method auxiliary function called lagrangian function this combination function maximize here equality constraint function where called lagrange multiplier dropped constant since effect optimization search stationary points lagrangian pairs satisfying note that second equality equivalent equality constraint optimization problem first equality leads here lagrange multiplier acts scaling constant required satisfy constraint evaluate this scaling factor lecture september fall once again order check that indeed local maximum would also have verify that hessian likelihood negative definite however here concave function hessian this means according section that being stationary point sufficient condition global maximum multinomial model similar binomial model from section relative frequency observation vector again follows intuition note that which also constraints geometric interpretation lagrange multipliers method lagrange multipliers method applied solve constrained optimization problems form with this generic formulation lagrangian with lagrange multiplier order find optimum search stationary points lagrangian pairs such that latter equality always equivalent constraint whereas former rewritten stationary point lagrange multiplier scaling factor between gradient vectors geometrically this means that these vectors parallel levelsetsoff 
 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe bastien lachapelle disclaimer these notes have only been lightly proofread statistical decision theory formal setup statistical decision theory formal setup analyze decision rules context uncertainty standard problem statistics estimation hypothesis testing will that also supervised learning problem from machine learning though people less used this machine learning random observation would training dataset which used sample space possible values that where distribution over suppose that belongs certain distribution sometimes have that distribution parametrized parameter which case note this distribution represents unknown state world there source uncertainty possible actions will denote certain action statistical loss function loss doing action when actual distribution when world decision rule less formally observe something from nature actually know mother nature generates observations know even suppose that belongs certain distribution context where have choose action among certain actions given facts that choose action that actual reality must certain cost since observe realisation makes sense base action this observation this decision process described important subtle point often will describe process xnqwhere siid this case often just write dependence loss terms instead full joint note that framework also works lecture september fall data this lecture only consider data when write mean distribution joint examples estimation suppose belongs parametrized family distribution call that belongs parameter space denoted pose this context estimator pose following loss function famous squared loss sometimes note instead where this simplification applies remember that this specific case write suppose more specifically that where siid this mean would have pdqq pdqk concrete example suppose that belongs gaussian family would mean that example could choose decision function hypothesis testing where might mean rejecting null hypothesis might mean accepting this context describes statistical test machine learning prediction ynqq have that that call input space output space siid then where joint over couples functions maps prediction setting define prediction loss function this function usually measure distance between given prediction associated ground truth actual loss function would like minimize rlpy fpxqqs this traditionally called generalization error also often called risk machine learning simon calls vapnik risk distinguish from frequentist risk from statistics that will define later this context decision rule actually learning algorithm that outputs function equivalently write that lecture september fall procedure analysis given this framework compare different rules procedures given know which better given application frequentist risk first property analyze procedure called risk frequentist risk edsp rlpp pdqs remarks risk function know what practice never really know what value this function given rule other hand this property theoretical analysis device make statement like some family procedure lower risk than procedure thus better some sense also important distinguish frequentist risk from generalization error vapnik risk next graph expose risk profiles rules simplicity suppose that parametrized distribution that this picture illustrates fact that sometimes there clear winner when comparing rules this case seems that best choice values near values from best choice problem know value know best rule pick will later that there fact ways bypass this problem domination admissibility that decision rule dominates another decision rule given loss function that decision rule admissible dominates lecture september fall theory aside point your culture alternative frequentist risk approach approach which common machine learning theory stands probably approximately correct instead looking average loss over datasets like frequentist risk does looks tail bound loss bound such that know that loss will smaller than with high probability this called given certain loss function decision function distribution over possible small real number theory seeks find bound such that prtlpp pdqq note that could have write instead emphasize fact that this bound depends next graph shows density pdqq given remember that pdqq random variable since random variable allow compare frequentist risk mean approach approach tail bound comparing decision rules would like able compare rules together figure which choose could find rule that dominates other rules would choose this rule often find such rule this there universally best procedure frequentist approach analyze different properties decision rules user then choose which they prefer according which properties better them present standard ways statistics reduce risk profile curve scalar then compare rules together notion optimality minimax criteria following this criteria optimal rule given minimax words minimax optimal rule rule minimizes risk would obtain worst possible scenario lecture september fall weighting this criteria requires that define weighting over interpreted prior formally weight intuitively when considering certain rule averaging risk over possible putting more weight believe more important phenomenon that studying after that compare them with each other pick rule corresponding lowest average bayesian statistical decision theory last criteria were making fact that observed data that observed realization bayesian optimality criteria makes this information before defining this criteria define what call bayesian posterior risk where posterior given prior optimal rule following bayesian criteria bayespdq recall bayesian philosophy treat uncertain quantities with probabilities posterior summarizes information need about uncertain quantity bayesian statistical loss then tells optimally simply need find action that minimizes bayesian posterior risk integrated there more uncertainty about thus only bayes procedure bayesian life quite easy bayesian need worry about other properties like minimax frequentist risk bayesian does care about what could happen other only cares that given specific observation want know given frequentist still decide analyze bayesian procedure from frequentist risk perspective particular show that most bayesian procedures admissible unlike also show that bayesian procedure optimal procedure when using weighted risk summary with weight function which matches prior this seen simple application fubini theorem from diamond graph below lecture september fall where stands conditional where where denotes posterior bayesian procedure property that minimizes weighted summary exercise given show that bayespdq posterior mean examples estimators maximum likelihood estimator mlepdq where likelihood function given observation maximum posteriori where posterior distribution over possible method moments suppose have that with siid being scalar random variables where vector idea find bijective function that maps vector moments mkpx perx basically mkpx qsince bijective invert pmkpx intuition that approximate could evaluate function using input empirical moments vector mkpx perx where erxj given this would method moments estimator lecture september fall example suppose that siid have that this defines function invert relation then finally replace moments empirical moments estimator here this estimator same estimator this illustrates property exponential family will this later this class note method moment quite useful latent variable models mixture gaussian spectral methods tensor decomposition methods recent literature prediction function estimation this context decision rule function called hypothesis space looking function that minimizes generalization error formally edsp rlpy fpxqqs fpyx since know what compute edsp rlpy fpxqqs replacement consider estimator erlpy fpxqqs where rlpy fpxqqs lpyi fpxiqq stands empirical risk minimizer here vapnik risk tensor decompositions learning latent variable models anandkumar jmlr lecture september fall convergence random variables convergence distribution general that sequence random variable txnun converges distribution towards random variable fnpxq fpxq where correspond cumulative functions respectively such case note convergence general that sequence random variable txnun converges norm towards random variable xkkks such case note convergence probability general that sequence random variable txnun converges probability towards random variable tkxn such case note note turns that convergence implies convergence probability reverse implication true properties estimator suppose that that siid will note npdnq estimator subscript stands emphasize fact that estimator value depends number observation bias estimator biasp lecture september fall standard statistical consistency that estimator consistent parameter converges probability toward consistency that estimator consistent parameter converges norm toward bias variance decomposition consider will express frequentist risk function bias variance remark other loss functions would have potentially different function bias edsp biasp variance thus expressing different priority between bias variance james stein estimator james stein estimator estimating mean siid dominates estimator squared loss when thus showing that lecture september fall inadmissible this case turns that james stein estimator biased that variance sufficiently smaller than variance offset bias properties assuming sufficient regularity conditions have consistent where fisher information matrix asymptotic optimality among unbiased estimator scalar parameter with lowest variance asymptotically this results follows from cram bound result which stated like this unbiased estimator scalar parameter then have that note that this result also stated multivariate case invariance reparametrization suppose have bijection then mleq this result generalized case where bijection suppose bijective define profile likelihood ppdata also define generalized this case then have that mleq this called plug estimator because simply plugging value function examples pmle mleq psin qmle sinp mleq 
 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe zakaria soliman disclaimer these notes have only been lightly proofread linear regression motivation want learn prediction function where binary classification multiclass classification regression problem there several perspectives modeling distribution data generative perspective here model joint distribution make more assumptions this case this leads less robust predictions more flexible approach sure what task trying solve conditional perspective only model conditional probability early called discriminative perspective simon prefers refer conditional approach fully discriminative perspective models directly estimate function using loss information this approach most robust linear regression model take conditional approach regression assume that depends linearly linear regression model following form lecture september fall where parameter weight vector equivalently could also rewrite model where noise random variable that independent remark note that there offset that will offset notation where constant feature thus have where bias offset training conditionally random variables whatever each response observation consider conditional likelihood outputs given inputs indep have that taking likelihood gives following expression notice that maximizing likelihood comes down following minimization problem find minw define design matrix lecture september fall denote vector coordinates this notation allows rewrite residual squares more compact fashion thus rewrite likelihood finally minimization problem over rewritten find minw remark minimization also viewed geometrically choosing that vector orthogonal projection onto column space find using normal equation invertible there unique solution then full rank invertible this case could pseudo inverse choose minimum norm solution amongst minw problem face that pseudo inverse numerically stable latter case would better regularization techniques next section lecture september fall ridge regression either interpret ridge regression adding norm regularizer least square replacing with adding prior where prior over have that then notice that always invertible remark strongly convex there unique global minimum remark good practice standardize normalize features standardizing means make features have empirical zero mean unit standard deviation normalizing mean different things scale them unit norm logistic regression turn attention classification problems this model will assume that make additional assumptions apart that densities goal model lecture september fall figure sigmoid function where class conditional ratio prior ratio odds ratio general have where sigmoid function shown figure lecture september fall sigmoid function following properties property property example finally make following observation that very large class probabilistic models yield logistic regression types models thus explaining logistic regression fairly robust consider that class conditional exponential family where thus have logistic regression model with features 
 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe eeshan gunesh dhekane younes driouiche disclaimer these notes have only been lightly proofread logistic regression about logistic regression turn attention binary classification problem define problem learning from input data usually subset some labels usually denoted there major approaches classification problem generative discriminative generative approach models distribution input data along with distribution labels given input data discriminative approach other hand models only distribution labels given input data logistic regression discriminative approach problem binary classification this approach only model learn required distributions where represent random vectors corresponding input data corresponding labels respectively despite this simplicity modeling problem logistic regression robust approach this because many other models share form with that this model begin discussion logistic regression with mathematical formulation formulation denote random vector that corresponds input data assume that some denote random variable corresponding labels input data binary classification problem assign values labels thus have goal model learn which distribution labels given input data model distributions functions form distributions chosen sigmoid function linear transformation will reasons later thus have where parameter model this form gives expression target distribution bernoulli lecture september fall denote given dataset with then goal learning becomes problem learning from given dataset which will consider through next sections generative motivation optional stated earlier that logistic regression fairly robust approach also defined function particular form this subsection provide generative motivation that tries justify these statements definitions this make major assumptions except existence probability density functions these distributions called class conditional distributions starting with class conditional distributions goal obtain following manner thus from previous equation where sigmoid function here odds ratio defined follows class conditional ratio prior odds ratio note that major proportion common distributions used modeling special cases exponential family distributions will study this later course distribution specified functions defined given below linear cannonical parameter pexp sufficient statistics partition function pexp then write from terms weight vector feature with lecture september fall thus generative model with class conditionals exponential family yield which precisely logistic regression model with feature concrete example exercise reader with multivariate gaussians exponential family then have that this linear regression model otherwise different covariances different classes then also assignment note that does appear definition even though does influence distribution given class conditional this means that there many different generative models which gives same model thus logistic regression model robust changes these choices which what meant saying that logistic regression more robust model than generative model approach sigmoid function properties this section provide quick review some properties sigmoid function formally defined follows figure shows graph sigmoid function over figure sigmoid function below some important properties sigmoid function prove using exercise lecture september fall property property property limz limz maximum conditional likelihood recap from subsection formulation have following model thus bernoulli equivalently maximum conditional likelihood from subsection formulation also that problem modeling becomes problem learning from dataset will method maximum conditional likelihood estimate parameter model given dataset conditional likelihood order solve first need find stationary points where have towards this define follows then have evaluate follows thus required expression lecture september fall solving turns that what known transcendental equation such equations often hard solve have closed form solutions thus left with choice using numerical methods find maximum conditional likelihood estimate next section provides description some useful numerical methods remark consider then encode both cases equation follows remark contrast transcendental equation obtained logistic expression approach obtained linear equation case least square regression approach recall that obtained hence solving setting essentially solving linear equation numerical optimization start with function defined some variable over domain want solve problem minimizing over this domain minimize over minw case thus domain gradient descent order method motivation motivation this approach fact that gradient function points direction maximum increase function thus order minimize function natural decision follow direction maximum decrease function this achieved traveling direction opposite that gradient algorithm gradient descent algorithm described below initialize update iterate converged update step lecture september fall here size step iteration hyperparameter needs chosen appropriately note that very small value then convergence very slow however very large value then algorithm converge diverge instance thus need have conditions heuristics choose properly some step size rules heuristics step size constant this constant chosen equal where lipschitz constant lipschitz constant vector function smallest number such that domain function have decreasing step size rule where constant heuristic behind this that want able cover domain achieved having however also want deviate away that converge solution achieved having choose solving where direction update this method called line search however since this approach general costly approximate search newton method order method motivation here approximate given function terms quadratic approximation relatively easy optimize quadratic function rather than given function which might have desirable convex concave nature taylor expansion given function obtain quadratic approximation follows taylor remainder quadratic approximation where here hessian function quadratic approximation function update formula obtained minimizing this quadratic approximation rwqt example have armijo line search conditions more details please refer book convex optimization stephen boyd lieven vandenberghe lecture september fall damped newton method order stabilize newton method incorporate step size update step given follows algorithm algorithm damped newton method given below initialize update iterate until some condition update step advantages disadvantages convergence newton method usually gives much faster convergence terms number iterations compared gradient descent method however each iteration newton method more costly than that gradient descent method specifically gradient descent update takes time space because need manipulate dimensional vectors gradients however newton method involves calculation inverse hessian which requires space takes time thus there trade number iterations till convergence versus complexity each iteration affine invariance role newton method affine invariant which means that invariant scaling variables reason behind this that update term newton method inverse hessian which transforms space make well conditioned demonstrate intuitive benefits this property effect presence hessian inverse following optional subsection role optional consider very simple example where have function minimize given where denotes component minimize this function using gradient descent newton method compute gradient hessian lecture september fall gradient descent newton method since hessian inverse proportional identity matrix gradient descent newton method have essentially same update steps except constants further update terms proportional thus updates from both directly along direction from global minimum however parameterize using thus same function function with compute gradient hessian follows gradient descent newton method that gradient descent proportional because hence direction update ideal because does point towards global minimum this effect parameterization however note that presence makes update term newton method proportional this makes direction update once again point towards global minimum thus that newton method affine invariant presence hessian inverse update step figures illustrate comparison gradient descent updates newton method updates elliptic loss function circular loss function respectively irls iterative reweighted least square formulation newton method applied logistic regression often called irls newton method solve transcendental equation encountered earlier recall lecture september fall figure elliptic loss function newton method updates point ideal direction whereas gradient descent updates this demonstrates role played inverse hessian newton method updates figure gradient descent updates newton method updates essentially identical except scaling constant given initialization parameter they both point ideal direction coincident lecture september fall from that given vector then xixi negative semi definite concave newton updates would indeed maximize likelihood design matrix where have input data label corresponding then expressed here diagonal matrix defined based this notation newton method updates given follows dtzt here defined follows this definition along with update step expression from indicate that each time step essentially solving weighted least square problem this seen follows lecture september fall square matrix matrix square root diagonal entries since diagonal thus have xxxxxxthen ttttt leastsquaresestimation from previousequationandthe frompreviousclass design matrix defined design matrix defined minw minw minw thus solution above weighted least squares problem form which represents gaussian noise model thus takes form data dependent noise logistic regression data data constraints logistic regression term data often stands datasets with large number data points large value each element being vector high dimensional space large value with data there several constraints methods used model dataset using logistic regression have seen that second order newton method incurs time space computation inverse hessian case data large number thus cannot afford these order computation thus must resort first order methods have also seen that first order method gradient descent faster iterations however number iterations till convergence large thus need improve upon gradient descent method batch gradient descent consider called batch gradient descent update step which described follows lecture september fall update where represents gradient input feature however computation each iteration involves computations gradients features thus overall computations iteration which afforded thus batch gradient descent data thus resort stochastic gradient descent variants extensions discuss some representative methods following subsections stochastic gradient descent update step involves randomly picking input feature iteration plugging gradient descent formula gradient that feature formally update formula given update randomly pick iteration time instance evaluate gradient rfit input feature indexed update follows rfit this approach cheaper complexity computations performed each iteration however convergence this method very poor when compared against batch gradient descent method also very high variance this intuitively seen follows there certain inputs which gradient takes abnormally large values then update step will sway from ideal update direction huge amounts this good convergence since such samples will easily mislead updates some extent cater high variance using stochastic mini batch gradient descent here instead evaluating gradient single randomly picked feature evaluate averaged gradient over randomly selected batch features with indices update step described below update randomly pick indices iteration evaluate averaged gradient rfij update follows lecture september fall updates incur computations iteration appropriate choice afford these updates intuitively averaging gradients diminishes effects abnormally large gradients update which slightly improves decreases variance note that convergence analysis mini batch shows that there advantage mini batch size bigger than cost mini batch step times cost gradient reason that variance decreases when increases yielding smaller total number iterations reach specific accuracy however this reduction number iterations smaller than thus each step times more expansive there overall gain using mini batch main computational reason mini batch when access parallel processing with parallel processors computation gradients made almost fast that only gradient this yields overall speed note that example approaches called incremental gradient methods optimization last years methods called variance reduced incremental gradient methods were proposed further speed these methods their idea reduce variance using memory present first these which breakthrough optimization literature stochastic averaged gradient small tweak called saga stochastic averaged gradient saga idea memory previous computations calculate update term update update here called memory variables every iteration update only memory variables rfit some randomly picked keep previously memory variables unchanged simply their computed values from previous iterations this method incrementally computing approximated gradient decreases variance method considerably particular allows constant step size like gradient descent which convergence much better than disadvantage that expectation over random choice update direction equal biased because that convergence proof very complicated with tens pages with numerically found quantities saga method small change make update direction unbiased significantly simplifying convergence proofs lines update step saga paper minimizing finite sums with stochastic average gradient lagrange prize mathematical programming lecture september fall update rfit variance reducingcorrection that variance reducing correction term zero expectation over thus yielding unbiased update direction expectation saga default method optimizing logistic regression scikit learn library figure summarizes characteristics methods discussed above figure comparison batch gradient method deterministic stochastic gradient method method stochastic saga hybrid methods method converges faster each update costly method cheap updates converges slowly hybrid methods best both worlds these methods achieve faster convergence with cheap updates further above notes were just quick introduction topic these methods covered greater details class advanced structured prediction optimization scikit learn standard libraries python based machine learning more information saga please refer original nips paper saga fast incremental gradient method with support strongly convex composite objectives 
 probabilistic graphical models fall lecture october lecturer simon lacoste julien scribe eeshan gunesh dhekane disclaimer these notes have only been lightly proofread fisher linear discriminant analysis consider problem binary classification last class considered logistic regression which discriminative conditional approach binary classification this class consider linear discriminant analysis which generative approach binary classification recall that conditional approach models only predictive distribution labels given input data other hand generative approach models input data well specifically models entire dataset distribution through gaussian class conditional distributions bernoulli prior distribution parameters involved this modeling easily learned from training dataset using closed form maximum likelihood estimates having learned parameters predictions easily made test dataset through predictive distribution following sections will consider approach detail however begin with brief introduction vector matrix calculus followed plate notation graphical representation probabilistic approaches vector matrix calculus motivation recall that definition derivative real valued function real valued variable given follows function said differentiable limh exists finite value value limit limh often denoted called derivative notion derivative function extremely useful modeling rate change points extrema linear approximation thus want extend note that linear discriminative analysis generalizes fisher linear discriminant method which uses linear combination features data classification simplicity will denote fisher linear discriminative analysis throughout notes lecture october fall this notion broader class functions specifically want define derivative vector matrix valued functions vector matrix argument clear from that same definition used directly generalization because involves limit fraction vectors matrices notion fraction division always well defined however rewrite follows limh equivalent where error function that satisfies limh this form definition derivative easier generalize desired broader category functions involves writing change value function asthe linear operator acting change argument function error function note that linear operator defined entirely terms acts change argument also error function must satisfy limh with these observations generalize definition derivative generalizing differentiability first consider vector valued functions vectors definition differentiability consider function such that differentiable linear operator such that here represents error function such that limk term usually called read little linear operator called differential differential linear operator remark differential operator thought machine processor which inputs vectors from processes them generates output vector should noted that this operator entirely defined terms should linear operator thought machine that inputs variable from domain space processes yields output target space will briefly consider exact meaning operator next subsection however will describe form these operators specific cases interest lecture october fall remark case differential takes form matrix with order operation becomes matrix multiplication details given below then differential represented matrix order called jacobian matrix denote component then where component component remark this definition differentiability differential from gives define derivatives only cases vectors also matrices tensors easy that exactly same definition will continue hold more general cases matrices tensors however needs careful about form differential remark another important case consider that real valued functions square matrices important required estimations corresponding gaussian distributions case differential takes form matrix with order operation becomes trace matrix multiplication details given below then chain rule most important frequently used formula evaluation differentials composition function chain rule expresses differential composition functions terms differentials individual functions follows then term product jacobians remark easy extend chain rule composition more than functions exercise also note that resultant product jacobians will always well defined lecture october fall important examples this subsection consider some examples that only help demonstrate definition from order calculate differentials certain important functions build required tool analysis subsequent sections differential squared mahalanobis distance such that have where constant vector order evaluate differential consider following manipulations where dimensional zero vector clearly limkhk thus definition have where dimensional identity matrix consider such that have where fixed matrix order order find differential consider following manipulations also easy prove that limkhk this exercise thus definition have consider matrix inverse covariance matrix some gaussian distribution with then squared mahalanobis distance with respect given gaussian distribution denoted defined follows note that term appears likelihood expressions involving gaussian distributions hence need evaluate differential order solve estimates consider following manipulations getting required differential extra information please refer wikipedia page mahalanobis distance lecture october fall define such that have where denotes function composition here functions defined above thus differential computed using chain rule follows since symmetric have thus remark calculation differential must ensure that error function denoted tends strictly faster than almost cases will deal with vector matrix tensor values thus default will consider frobenius norm matrix including vector defined follows frobenius norm vector matrix denoted ktkf frobenius norm vector defined kvkf frobenius norm matrix defined kmkf differential determinant square matrix another important function that appears whenever consider likelihood involving gaussian distributions logarithm determinant covariance matrix thus important consider differential determinant matrix function defined consider matrix then simplicity restrict proof symmetric matrix that strictly positive definite this implies that invertible that matrix square roots exists spectral theorem such that denote call square root matrix note that always find square root real valued symmetric matrix hence proof will work cases when equals covariance matrix gaussian distribution inverse matrix denote eigenvalues decreasing order with multiplicity counted then will extra information frobenius norm please refer wikipedia pages matrix norm frobenius inner product more information square roots matrices their existence construction please refer wikipedia page square root matrix lecture october fall following standard linear algebra properties derivation matrices have matrix that diagonalizable have matrices have matrix have xxxx consider derivation obtain differential determinant thus definition differential determinant using standard notation have remark optional proof above small jump after expanding terms error function terms where need prove that limk prove this follows observe that eigenvalues thus square matrix dkbkf second last inequality follows from root mean squares inequality matrices cauchy schwarz inequality gives called root mean squares inequality forms special case broad category important inequalities involving generalized mean concise reference these inequalities found wikipedia page generalized means inequality lecture october fall this gives required limit every using squeeze theorem limits have since from derivation have limk limk thus limk this completes proof that error function indeed tends zero strictly faster than simply replace ugly expression error function references details related matrix calculus please refer book matrix differential calculus with applications statistics econometrics neudecker magnus plate notation graphical representation motivation before begin with analysis take look method graphical representation probabilistic approaches called plate notation here represent probabilistic approach graphical format that easy visualize picture worth thousand words probabilistic model want model uncertainty some random variables vectors parameters then learn corresponding underlying distributions assume that rest random variables vectors parameters fully known hence want model uncertainty these variables graphical model need rules represent these different sets variables clearly further dependencies between various random variables parameters under consideration should clearly represented addition might happen that scenario huge number random variables parameters that need considered dataset with samples then need represent repeated variables diagram concise well precise manner towards this consider following rules define graphical representation method note that there multiple conventions setting dimensions derivatives imperative that stick particular convention order consistent results definition from results answers that abide called numerator layout this context good reference point checking final answers expressions derivatives wikipedia page matrix calculus more information please refer wikipedia page plate notation note that rules graphical representation probabilistic models vary from different sources wikipedia reference plate notation gives such sets rules graphical representation lecture october fall rules graphical representation plate notation random variables parameters which want model uncertainty represented circular nodes with variable names random variables parameters that assumed known which model uncertainty represented square blocks with variable names dependencies between various random variables parameters represented using directed arrows random variable observed then circular node corresponding shaded observed then circular node corresponding shaded note that rules above help convention graphical representation probabilistic approaches however need cater cases where variables repeat called plate notation help conventions concisely representing repeated variables model rectangle also called plate group together inside random variables parameters that repeat together each variables plate indexed range index mentioned plate order expand representation repeated contents plate arrows that cross plate represent directed arrow repetition plate figure illustrates these rules with help example figure example graphical representation involving plate notation note that parameter assumed known uncertainty modeled there random variables which want model uncertainty dependent only random variables dependent parameter only observed variables observed note that figure left represents this model concisely using rules graphical representation plate notation equivalent expanded graphical representation shown right lecture october fall analyis formulation consider analysis generative model binary classification denote random vector corresponding input data such that denote random variable corresponding binary label input represent labels thus model input data modeling entire dataset terms class conditional distributions prior distribution assume following forms distributions bernoulli some here mean class represents covariance matrix with notice that assumes that covariance matrix same both classes class class figure schematics scenario which best modeled note that class conditional distributions have different means same covariance matrix input dataset then problem modeling dataset becomes problem estimating parameters that define class conditional prior distributions will joint maximum likelihood estimation estimate these desired parameters lecture october fall maximum likelihood estimation optional formulate maximum likelihood problem follows likelihood datapoint thus likelihood each datapoints thus likelihood entire dataset optimize find stationary points with respect parameters will results differentials important functions evaluating formulae number datapoints with label equal thus lecture october fall with post multiplying gives thus derivation needs some manipulations standard properties needed this listed below will also expression differential determinant scalar trace thus provided products well defined thus thus symmetric thus reparametrizable will evaluate rather than easier since thus thus thus lecture october fall remark note that still remains proved that these estimates indeed maximize objective exercise details related optimization numerical computation please refer convex optimization boyd venderberghe deep learning book goodfellow bengio courville predictive distribution inference optional having modeled entire dataset estimating required parameters next step apply this model predict class test data this inference carried using predictive distribution follows test point predicted label otherwise thus need find expression which below thus from previous equation where sigmoid function here odds ratio also called scoring function defined follows class conditional ratio prior odds ratio from have lecture october fall also have observe that scalars further because thus from with thus where with remark note linear decision boundary covariances been different decision boundary would have been quadratic curve conic section remark note that fisher models generative approach models whereas logistic regression discriminative approach models both approaches predictive inference rule based evaulating test input lecture october fall lecture october fall previous exercise shows that despite difference approaches predictive inference rule fisher logistic regression have essentially same form form logistic regression where some further incorporate bias constant logistic regression make scoring function generalized linear scoring function easy that thus replace with equivalent generalized logistic regression thus that generalized logistic regression fisher both have same inference rule sigmoid linear function datapoint also inference rule basic logistic regression fisher essentially same except bias term scoring function remark graphical representation given done figure where exercise find graphical representations linear logistic regression approaches figure graphical representation using plate notation unsupervised learning views unlabeled data till have consider scenarios modeling datasets input data points corresponding labels however there numerous real life problem settings where have access labels corresponding data thus without labels want model data there ways consider unlabeled data mixture distribution approach latent variable approach order understand these approaches better consider example unlabeled data figure given data viewed mixture several component distributions instance data distribution figure viewed mixture gaussian lecture october fall cluster cluster figure there views unlabeled data view mixture distribution consider data terms latent variables example appears though data coming from different groups clusters hence finding characteristics these structures order learn underlying structure distribution however easily visualize data coming from groups clusters such that points from same cluster very similar another those from different different from another thus understand structure data better manner trying model these clusters however since cluster assignment data points available unsupervised problem call clusters latent variables learn latent variables from available data difference approaches also seen from their plate diagrams which given figure this scribe will only consider latent variable approach figure graphical models mixture distribution approach left latent variable approach right here represents unlabeled data represents assumed latent variables corresponding data point lecture october fall means algorithm motivation consider problem clustering given unlabeled data want learn cluster assignment function that predicts cluster which each data point mapped assume that there clusters data which labeled represent each clusters representative cluster center idea that data points that belong particular cluster center should differ much from corresponding cluster center measure this extent difference using distortion function which defined terms chosen distance function since have information about cluster centers initialize them randomly then perform iterative algorithm starting with guess cluster assignment function which maps each data point some cluster center then update cluster centers that distortion measure minimized intuitively this step makes guess cluster centers better however with better guess cluster centers better cluster assignment function thus repeat these steps decrease distortion function until converge best cluster centers cluster assignment function formulation will following notations observations want partition means where center cluster will denote associated matrix indicator variables associated such that belongs cluster otherwise matrix which components equal distortion function define distortion kkxi algorithm algorithm minimize proceed with alternating minimization block coordinate minimization initialize cluster centers minimize with respect mins other words associate nearest center minimize with respect come back step until convergence remark step minimization with respect equivalent allocating voronoi cells which centers remark during step minimization with respect obtained setting zero coordinate gradient with respect indeed easily that lecture october fall properties means converges finite number iterations local minimum however just local general hard find best cluster assignment general implies that there cases which require time exponential input size there certain cases where there very easy solutions very fast requires lesser number iterations initialization very important means there algorithm means which gives clever initialization scheme that guarantees that objective within global optimum with high probability there theoretical guarantee spread initial mean points much possible this avoids wrong clustering image class select means inverse their distance from previous means choice heuristics regularization term hyperparameter need experiment with value later class will parameteric models where basically infinite data example dirichlet process mixture model effect optimal value means very sensitive distance measure used when using getting spherical clusters also choice clustering depends problem itself different objectives will have different best choices clustering which will decided different distance measures figure class clustering actually good clustering mail problem problem previous figure fixed gaussian mixture model convergence initialization show that this algorithm converges finite number iterations therefore convergence could local thus introduces problem initialization classic method random restarts consists choosing several random vectors computing algorithm each case finally keeping partition which minimizes distortion thus hope that least local minimum close enough global minimum other well known method means algorithm which aims correcting major theoretic shortcomings means algorithm approximation found arbitrarily with respect objective function compared optimal clustering means algorithm addresses this obstacles specifying procedure initialize cluster centers before proceeding with standard means optimization iterations with means initialization algorithm guaranteed find solution lecture october fall that competitive optimal means solution intuition behind this approach that clever thing well spread initial cluster centers each iteration algorithm will build center will repeat algorithm until have centers here steps algorithm first initiate algorithm choosing first center uniformly random among data points each data point your data compute distance between nearest center that already been chosen denote this distance where specified recall that minimizing over current chosen centers choose data point random center using weighted probability distribution where point chosen with probability proportional repeat step step until centers have been chosen that have built vectors with respect first intuition which well spread centers because used well chosen weighted probability those vectors initialization standard means algorithm more details found means algorithm arthur vassilvitskii means advantages careful seeding proceedings eighteenth annual siam symposium discrete algorithms 
 probabilistic graphical models fall lecture october lecturer simon lacoste julien scribe martin weiss eeshan gunesh dhekane disclaimer these notes have only been lightly proofread graph theory review directed graph definition directed graph consists nodes vertices edges such that ordered pairs distinct vertices will only consider graphs that have self loops figure directed graph with definition directed path from vertex vertex directed graph consists ordered sequence vertices where such that denote this directed path from squiggly arrow equivalently directed path also viewed sequence edges mentioned above same path represented ordered sequence edges example given below shows directed path from figure definition parents vertex denoted vertices from which there edge analogously children vertex denoted vertices which there edge from figure below shows parent which children which lecture october fall figure directed path from with vertices edges figure parent children undirected graph definition undirected graph consists nodes vertices edges such that sets without self loops thus edge identical edge since there self loops edge have figure shows example undirected graph figure undirected graph definition undirected path from vertex vertex directed path consists ordered sequence vertices where such that equivalently undirected path also viewed sequence edges mentioned above example given below shows directed path from figure lecture october fall figure undirected path from definition neighbors vertex denoted vertices that connected with through edge undirected graph neighbors replace notions sets parent children figure shows neighbors vertex figure vertex with neighbors directed acyclic graph definition cycle directed undirected graph consists ordered sequence nodes such that there exists directed undirected edge from there exists directed undirected edge from equivalently there exists directed undirected path from some vertex examples directed undirected graphs above there cycle directed graph however there cycle undirected graph namely definition directed graph with cycles called directed acyclic graph note that directed graph considered indeed directed acyclic graph definition ordering vertex directed graph said topological only bijective implies that lecture october fall what this deinition implies that order increasing manner vertices based topological ordering will always have parent node appearing before node itself directed arrows would point right leaving back edges observe that from figure ordering vertices already topological ordering which displayed figure figure example topological ordering from figure theorem characterization dags using topological ordering directed graph topological ordering proof given perform depth first search algorithm number descending order nodes which children while performing because there cycle will always find nodes with children during this algorithm thus this generate topological ordering time trivial there topological ordering then have back edges hence have cycles thus notation graphical models given random variables assume that discrete random variables simplicity this part class this because defining conditional distribution continuous random variables challenging please refer borel kolmogorov paradox challenges defining conditional distributions given graph such that associate random variable node letting random variable associate with node subset vertices defined easy that where denotes summing over possible values instance represents joint probability given lecture october fall about graphical models graphical model essentially graph that models dependencies between random variables graphical models intersection probability theory computer science that they graphs model distributions over random variables graphs highly efficient data structures storing information related dependencies thus they extremely useful case modeling distributions instance consider random variables then order represent distribution table format would require variables which intractable represent explicitly computer contrast graphical models with certain assumptions keep problem tractable conditional independence revisited three subsets vertices that this factorization forumulation equivalent conditional formulation states that state marginal independence facts about conditional independence repeat variables allowed repeat variables conditional statement convenience example fine actually equivalent second left does anything this will useful when writing generic theorems about conditional statements from graphical model avoid excluding repition cases decomposition implies both decomposes conditional independence statements directed graphical models definition with directed graphical model associated with also known bayesian network family distributions lecture october fall over defined follows distribution over legal factors definition above legal factors functions thus like conditional probability table could used define conditional distribution given values parents notes recall that parents node definition above factors have unique rule possibility that same distribution could have expansions with different factors turns that actually prove that factors unique will when show that below thus factors uniquely specified distribution terminology write where legal factors determined from then that factorizes according denote this also member will also sometimes write want make which variables considered distribution explicit notation proofs below give example three nodes graph from figure then this graph only there exists some legal factors leaf plucking property first show fundamental property which used proofs proposition leaf plucking property leaf parent anything suppose then then proof there definition lecture october fall this property show important fact that factors same conditional probabilities defined from joint thus factors correct conditionals proposition then proof prove this induction cardinality since there exists leaf node with children without loss generality assume that leaf labeled then just relabel nodes that true first notice step justified fact that leaf thus never appears step also justified same kind reasoning since leaf cannot appear explaining only function from this result induction reasoning noticing that still conclude this proof simply need show that indeed this property will automatically propagates induction have noticing that function only derive hence give equivalent definition notion factorization lecture october fall definition equivalent definition distributions that factorizes according denoted didn start with above definition reason that without proof above would know whether definition makes sense this definition circular indeed conditional defined from joint allowed normally define joint multiplying conditionals might distribution that satisfies this property remark adding edges more distributions with subset then subset examples trivial graphs example trivial graph with empty edge assume there edges then this graph contains only fully independent distributions this smallest complete digraph assume have complete graph thus with edges need acyclic have called chain rule which always true thus distributions belongs complete graph this biggest graphs with three nodes give insight different possible behaviors graph thoroughly enumerating possibilities node graph first options empty graph leading independence complete graph that gives further information than chain rule markov chain markov chain certain type showed this configuration show that have have that future conditionally independent past given present assuming arrow would represent time other there lecture october fall some distributions which marginally independent dependence flows through show conditional independence statement have figure markov chain latent cause type given show that indeed figure latent cause explaining away represented show this type graph basically stems from other hand general have that conditionally independent given unlike both latent cause model markov chain here marginally independent observing induces some dependence between lecture october fall figure explaining away structure from this graphical model called motononic property conditioning example abducted alien watch broken late structure explains this situation there competing explanation late might have been abducted aliens watch could broken notice time this example meaningful distribution could yield that alien tiny then alien late alien because knowing that late give some evidence that perhaps have been adbucted alien alien late broken watch alien late because that know that watch broken gets unlikely again that have been abducted alien more likely that late because watch thus conditioning more things increase decrease probability event hence word monotone remark cause advised since observational statistics provide with correlations causality notion note also that explaining away graph general true lastly important remember that every relationship expressed terms graphical models counter example take function where three random variables pairwise independent mutually independent conditional independence statements dgms definition path from then said nondescendent proposition then proof will only prove forward implication assume topological order then because chain rule always true lecture october fall chose topological order have show induction that this directly implies that idea notice that there exist topological order such that separation want answer queries such given three subsets true answer those issues need separation notion directed separation indeed easy that notion separation enough directed graph needs generalized definition chain from sequence nodes such that notice that chain hence path symmetrized graph graph where relation true then true well assume that observed want define notion being blocked this order answer underlying question above figure separation definition separation chain from blocked node given either structure lecture october fall structure descendants chain from considered blocked blocked some node along said separated only chains that from blocked rules above example markov chain prove that future independent past given present with markov theory might difficult separation notion gives results directly figure markov chain hidden markov model often used because only observe noisy observation random process observationsetats figure hidden markov model proposition conditional independence statements such that separated bayes ball algorithm this intuitive reacheability algorithm determine conditional independence statements seperation suppose want determine conditionally independent from given place ball each nodes them bounce around according some rules described below reaches true none reached otherwise balls implement path rules from separation blocked accordingly rules follows three canonical graph structures note that balls allowed travel either direction along edges graph lecture october fall figure markov chain rule when observed balls blocked left when observed balls pass through right markov chain balls pass through when observe blocked otherwise children balls pass through when observe blocked otherwise figure rule when children when observed balls blocked left when observed balls pass through right structure balls pass through when observe blocked otherwise figure structure rule when observed balls blocked left when observed balls pass through right properties inclusion reversal marginalization inclusion property here quite intuitive proposition about included graphs their factorization lecture october fall proposition then proof have obvious that therefore going back definition graphical models through potential result reversal property also have some reversal properties first define notion structure definition there structure figure more parents proposition markov equivalence andif then reversed factorizes then factorizes with terms nodes graph this property ensures that markov chain latent cause equivalent also applying reversal property multiplle times conclude that directed trees built from undirected tree give same other hand structure lead different class graph compared others definition edge said covered figure edge covered reversing might might break acyclic property have following result proposition graph covered edge with then marginalization underlying question know whether marginalization distributions yield another show that marginalizing leaf node yield smaller graph marginalizing internal nodes might yield distributions which representable 
 probabilistic graphical models fall lecture october lecturer simon lacoste julien scribe philippe beardsell based scribe notes from jaime roquero jieying proofread quickly corrected simon lacoste julien general themes this class modeling high dimensional distributions representation represent family distributions examples convenient families given graphical models parametrization parameterize members family distributions example this that will using exponential family there many others inference compute where query evidence lecture elimination algorithm lecture product algorithm belief propagation statistical estimation estimate model from observations examples principles that maximum likelihood estimators maximum entropy method moments undirected graphical models markov random fields markov networks undirected graph cliques where clique fully connected nodes examples nodes which cliques from size lecture october fall associated with some potentials where normalizing constant partition function functions potential functions probability distributions unlike where could think node parents which implies potential directly related probability distribution remark multiply constant without changing because will normalize with therefore some undirected graph there multiple ways define probability example consider following graph could write could also write note that second equation rewrite simpler potential function form clique nodes potential function encompasses information about dependencies between nodes there loss generality making that transformation therefore sufficient consider only cmax maximal cliques where maximal clique clique that cannot extended including additional vertex restrict ourselves that case given that cliques subsets more maximal cliques then redefine note will later that sometimes convenient consider over parametrization trees using both property before lecture october fall trivial graphs consider with this gives that fully factorized that mutually independent consider with clique reduced single make conditional independence assumptions between distribution property then that exponential family negative energy function example ising model physics node potentials edge potentials another example could social network modeling lecture october fall conditional independence directed graphical models view undirected graphical models encoding independence assumptions their structure definition that satisfies global markov property with respect undirected graph only disjoint separates from then have figure separates from paths from must pass through proposition satisfies global markov property proof without loss generality assume consider case where then separated definition have disjoint union show that separated contradiction suppose there which separated there exists path from passing through then definition would contradicting definition cannot same time also have that original separated from thus have separated show that then decomposition property this implies subsets giving required general case thus continue proof with lecture october fall cannot have clique intersect both same time otherwise part would connected direct edges from this clique thus similarly thus this proves converse above theorem always true assignment assume that probability strictly positive holds given following deep theorem theorem hammersley clifford then satisfies global markov property proof chapter michael jordan book property closure with respect marginalization lecture october fall directed graphical models also have marginalization notion undirected graphs slightly different factorizes then factorizes graph where node removed neighbors connected edges connect neighbors together clique marginal definition markov blanket markov blanket node smallest nodes such that node conditionally independent other nodes given neighbors markov blanket node include parents children parents children children children table summarizes differences between moralization when transform undirected graph such that from same before answering this question first define undirected graph that lecture october fall table summary main differences between directed graphical model undirected graphical model factorization conditional independence separation many more separation marginalization closed general only when marginalizing leaf nodes closed cannot exactly capture some families grid structure definition call moralized graph where undirected graph with same vertices some undirected version moralization that moralization explained less formally connecting parents with clique note that only need edges when when there structure here examples this transformation note that conversion process from bayesian network markov random field loose marginal independence parents position answer original question when yields same note that terminology moralization come from fact that marrying parents adding edges between them thus from traditional christian point view making family moral lecture october fall proposition with structure forest then general only that note that minimal undirected graph such that proof this will done assignment proposition flipping covered edge that directed edge covered edge only suppose edge covered define with prove that proof note that order identify factors decomposition joint distribution provided with conditional distributions need show that indeed know that must prove that flipping introduce cycles recall that graph only topological order wlog assume that vertices original graph indexed with such topological ordering some sequence also topological ordering since then then topological ordering since everyone ancestors their left therefore thus have where denotes parents consider such that then chain rule valid distribution have covered edge have moreover definition have with parents note that equation interpreted simply swap terms product factorization lecture october fall then both above equal zero still equal thus have symmetry reverse argument thus 
 probabilistic graphical models fall lecture october lecturer simon lacoste julien scribe pravish sainath proofread quickly corrected simon lacoste julien inference motivation have seen about different types probabilistic graphical models their properties they model probability distributions encoding conditional independences find these graphical models answer specific questions about their distributions many situations want compute following probabilities from pgms marginal some conditional query nodes evidence nodes partition function normalization constant some situations that require inference determining missing data xunobserved xobserved example image infilling task computer vision prediction xfuture xpast example prediction next observation sequence time series identifying latent cause xcause xobservation example model quick medical reference diseases symptoms identify presence disease from observed symptoms related inference decoding maxxf example speech recognition identifying best sentence from speech data lecture october fall inference also needed sometimes when estimating parameters example when doing latent variable model need compute during step algorithm remark will present inference algorithms only ugms they simpler more general these applied dgms after converting them ugms using process moralization studied previous lecture joint probability distribution represented expressed equivalent follows moralization where idea graph eliminate algorithm main trick compute marginalization efficiently organize computation using distributivity property specific order this will yield graph eliminate inference algorithm that will describe soon distributivity property distributivity property reorganize probability expression distributivity over stated that functions have lecture october fall more generally suppose that each variables take values using this trick have transformed terms each including product values thus complexity product terms each which over terms thus complexity generalize this idea more complicated potentials graph elimination algorithm inference graph eliminate algorithm uses idea ditributivity successively eliminate variables summing over their values infer marginal probability query this called variable elimination graph eliminate algorithm present formal procedure graph eliminate algorithm compute marginal probability given query corresponding nodes from with cliques initialize choose elimination ordering such that nodes last nodes terms active list update repeat order variables eliminate pick variable eliminate from active list remove factors from active list that contains argument take their product product over variable factor where contains variables factors except clique over back active list call consistency notation lecture october fall normalize last factors left have only terms required probability proportional this needs normalized obtain final value illustrating example want compute probability distribution from whose graph given figure figure graph writing joint distribution factorized required probability expressed marginal joint probability summing over remaining variables splitting summation distributive property choose elimination ordering factors currently active list lecture october fall successively applying updates chosen order messages added active list removing factors containing eliminated variables probability distribution proportional message computed algorithm modifies original graph consecutively removing nodes passing messages other nodes that lead query node shown figure figure graph with computed messages lecture october fall properties graph eliminate algorithm memory cost suppose simplicity that each take values memory cost expressed terms number active variables each stage number factors active list maxi factors computational cost expressed terms number active variables each stage number nodes graph maxi augmented graph triangulated observed that cliques formed side effects while running algorithm running algorithm keeping track edges added between yields augmented graph that property being triangulated graph figure left triangulated graph right triangulated graph chord edge between neighboring nodes cycle definition triangulated graph graph with cycle size more that cannot broken chord other words cycle size broken chord triangulated graph illustrated figure during graph eliminate algorithm edges added turns that enough edges added ensure that resulting augmented graph triangulated example figure here black lines indicate original edges blue lines indicate edges introduced algorithm during elimination lecture october fall figure augmented graph after graph eliminate treewidth graph undirected graph treewidth defined treewidth size biggest clique over elimination orderings minus convention that treewidth tree treewidth tree both memory running time algorithm determined number variables largest elimination clique term size biggest clique algorithm tractable need achieve ordering giving minimum size largest clique which treewidth best ordering gives term treewidth complexities orderings good example removing central node node star graph gives large clique size leading very factor active list which computationally efficient seen figure whereas removing leaf nodes gives cliques size consistent with treewidth news about inference actually hard compute treewidth graph find best elimination ordering lecture october fall figure ordering star graph hard exact inference general thus instead need approximate inference methods general example treewidth grid graph with nodes actually growing with side grid shown figure later that ising models popular models computer vision they often have this grid structure later lectures will show approximate inference such using gibbs sampling variational method mean field these terms will defined later lectures figure grid graph with vertices good news about inference inference linear time graphs that trees treewidth product algorithm derived trees like hidden markov models markov chains efficient small treewidth graphs general graphs junction tree algorithm used 
 probabilistic graphical models fall lecture november lecturer simon lacoste julien scribe ismael martinez abdelrahman zayed disclaimer lightly proofread quickly corrected simon lacoste julien inference trees inference tree graph eliminate algorithm described last lecture using appropriate elimination ordering exemplified this corresponds marginalizing using distributivity trick good order perform graph elimination tree eliminate leaves first which makes sure that edges added augmented graph achieving treewidth maximal clique size figure applying graph elimination compute also apply graph elimination using root shown messages that passed from leaf nodes towards root computed according children factors containing active list where node child node lecture november fall figure using root node compute product algorithm trees product algorithm algorithm node edge marginals cheaply storing caching reusing messages using dynamic programming figure collect distribute phases compute marginal node arrows refer collect phase whereas green arrows refer distribute phase message from node node computed follows figure passing message from node node where neighbors lecture november fall using green arrows shown compute marginal node goal compute node only send messages neighbour when received messages from other neighbours message from node node computed according node marginal proportional factors left active list this message passing formulation proportional therefore edge marginal probability pair neighboring node node example computed follows figure computing marginal probability edge between node node want compute marginal pair nodes which adjacent then usually need more general graph eliminate algorithm example only works compute node marginals well edge marginals adjacent nodes could generalize argument made compute marginals more than nodes they connected taking product incoming messages boundary connected nodes well potentials connecting nodes lecture november fall figure example case where need graph elimination algorithm compute probability nodes green added edge appearing augmented graph when running graph eliminate there node ordering that choose with which would edges explaining product algorithm cannot used this example product schedule collect distribute schedule shown also flooding parallel schedule which works follows initialize messages uniform distribution every step parallel compute neighbour messages were correctly computed from previous step prove that tree diameter messages correctly computed fixed after steps they fixed points this update process product algorithm graphs with cycles loopy belief propagation whereas parallel iteratively computes messages tree loopy belief propagation provides general case approximate inference graphs with cycles loopy refers cycles initialise messages uniform distribution every step compute using convex combination domain between previous message calculation stabilize update where step size this approach known damping lecture november fall remarks this gives exact answer trees fixed point yields correct marginal tree algorithm doesn converge general right marginal sometimes loopy gives reasonable approximations getting conditionals used indicate fixed values conditioning keep variables fixed during marginalization each formal trick redefining potential function need worry about fixing variables redefine kronecker delta function otherwise computing stuff stuff result will give normalize over conditional lesson when graph eliminate over observed variables note product compute marginal product compute product algorithm main property used distributivity over require that semi ring need additive inverses product like algorithms other semi rings where replace operations same concepts second example above where product algorithm distributivity trick that mentioned previously motivate graph eliminate algorithm using this product semi ring takes form lecture november fall analogous where move from outside product inside move function from outside product inside message updates product algorithm become example example maxx maxx figure sequential message passing compute argmax store argument this function every product algorithm forward backtrack pointers full this algorithm decoding backtracking also known viterbi algorithm property tree tree with zero marginals then have proof idea similar define factors such that local consistency property holds then define joint show correct marginals lecture november fall figure store values forward pass backtrack pointers values this viterbi algorithm junction tree algorithm junction tree algorithm algorithm designed tackle problem inference general triangulated graphs generalization clique tree with junction tree property show clique tree with running intersection property then along path from tree that satisfies this property known junction tree build junction tree from triangulated graph maximum weight spanning tree clique graph where size separator sets weights edges clique graph other words spanning tree with maximum number nodes common among neighbouring cliques this tree will have running intersection property therefore junction tree theorem junction tree graph triangulated graph decomposable graph always turn graph into triangulated graph running graph eliminate algorithm once have junction tree show lecture november fall triangulated graph representation clique tree representation figure clique tree that follows running intersection property known junction tree junction tree shown here with dotted edges dotted edges additional edges present clique graph where edge between every pair cliques with some node common build spanning tree which running intersection property running maximum weight spanning tree algorithm clique graph with weight edges that size separator where separator sets junction tree junction tree algorithm reconstruct above formulation starting with where initialization message passing junction tree update potentials repeat step until convergence will have correct marginals 
 probabilistic graphical models fall lecture october lecturer simon lacoste julien scribe samuel beland leblanc disclaimer lightly proofread quickly corrected simon lacoste julien hidden markov model hidden markov model generalization latent variable model such gaussian mixture model example with added time dependence latent variables figure latent variable model example figure latent variable model with added dependence latent variable discrete later gaussian kalman filter observed variable continous speech signal discrete sequence lecture october fall from theory following joint probability emission prob transition prob often emissision probabilities transition probabilities homogeneous they depend hence have that named transition matrix stochastic matrix column transition matrix seen probability distribution over inference tasks there multiple inference tasks interest when using general task compute probability sequence hidden state given observable output sequence there also some marginal probabilities that interesting prediction where next filtering where term filtering comes from interpretation that output provides noisy information about underlying signal noisy signals filtered based value smoothing where past order perform these inferences need take advantage conditional independence involved graphical model when conditioning latent variables conditioning make independent future independent past given present this thus gives following note that some textbooks normalized convention instead normalized column simon prefers column convention then updates matrix vector products message passing updates later lecture october fall where recursion that will define recusion will product algorithm here derive recursions compute probabilities didactic example product ugms also derive these recursions directly instead figure visual representation recursion instead computing filtering distribution will compute joint marginal using message passing here using notation indicate that observation fixed marginalization lecture october fall with with note that above first equation because have node potential then define which expressed using above derivations making recursion explicit this recursion forward recursion like collect phase product algorithm using root also express matrix vector product from definition just proposed that vector matrix vector then using hadamard product redefine recusion like this initialization recursion simply also observe that renormalize over filtering distribution from also evidence probability time complexity matrix vector products over states repeated times space complexity only need extra storage alpha recursion note that takes store whole matrix transition matrix this given problem extra storage lecture october fall recursion smoothing figure visual representation recursion smoothing probability need also consider information this where beta recursion needed joint marginal observations have from conditional independence property explained earlier expanding message equation expose actual recursion with following initialization finally from product algorithm obtain edge marginal this seen observe anything marginalizing leaves there just yields value leaf plucking property lecture october fall numerical stability trick problem with doing inference amount multiplication values which makes that easily this underflow there tricks that used order avoid this general store instead imax then following imax normalize messages recursion previously defined filtering distribution initially possible show that hence recursion define note here that general will have reasonable value underflow advantage requiring much extra computation using stored values exercise derive recursion lecture october fall maximum likelihood first some parametric model gaussian where transition matrix since parents want estimate parameters from sequences data where have latent variable model going step iteration then step time simply recursion with parameters time step trying optimize this going complete likelihood look each term individually will able maximize with respect after soft counts smoothing distribution soft counts smoothing edge marginal lecture october fall maximize with respect this will depend parametric model used them using soft count maximum likelihood similar used gaussians weighted empirical mean just described what called baum welch algorithm consisting forward backward using recursion product with finally find maxz must viterbi algorithm product seen earlier 
 probabilistic graphical models fall lecture november lecturer simon lacoste julien scribe tapopriya majumdar disclaimer lightly proofread quickly corrected simon lacoste julien information theory kullback leibler divergence discrete distributions divergence between defined motivation from density estimation estimation given distribution recall statistical decision theory setting standard maximal likelihood loss loss giving following statistical loss when true distribution action note that above called cross entropy best action then loss entropy which obviously best outputting correct distribution therefore excess loss this case divergence interpreted excess loss outputting instead true distribution lecture november fall motivation from coding theory fact that coding theory optimal length code proportional bits then expected length code where entropy measured bits then divergence interpreted excess cost terms length code distribution coding opposed optimal distribution examples example entropy bernoulli distribution bern then which largest when example entropy uniform distribution states uniform then turns that uniform distribution states with maximum entropy among distributions over states properties this shown using jensen equality strictly convex each argument symmetric when maximal likelihood minimization parametric family distributions empirical distribution corresponding samples then when using natural base entropy measured nats when using measured bits lecture november fall proof xlog constant maximum entropy principle here idea consider some subset distributions over according some data driven constraint subset principle pick which maximizes entropy argmaxq argminq mdkl uniform uniform constant more generally also consider generalized maximum entropy principle where minq some distribution that want favor instead uniform which used standard maximum entropy soon role this when talk about equivalence maximum entropy with maximum likelihood exponential family example from wainwright observe kangaroos left handed kangaroos drink labatt beer then many kangaroos both left handed drink labatt beer here entropy solution that independence standard through empirical moments feature functions represent various measurements want make data then define that distributions which their model moments match empirical moments then constraint becomes some scalar linear lecture november fall equality when represented vector over elements hence finding using maximal entropy uniform such that becomes convex optimization problem over lagrangian duality segue convex functions affine functions here these functions extended real valued functions then primal convex optimization problem minimizexf such that define where langrange multipliers will present saddle point interpretation lagrangian duality uses following trick feasible feasible equivalent problem constrained primal problem following unconstrained problem using fancy complicated function duality trick swap lagrangian dual problem infx that always concave both components lagrangian dual problem solve lecture november fall weak duality infx always true because always feasible then strong duality when have equality when primal optimization problem convex sufficient condition strong duality slater condition such that where nonlinear feasible chapter boyd book http stanford boyd cvxbook more details note that after solving dual problem obtaining usually reconstruct primal optimal variables when strong duality holds using conditions which necessary linear equations that hold primal dual optimal variables dual problem maximal entropy uniform distribution then primal form maximal entropy problem find lecture deriving maximum likelihood parameter multinouilli will ignore inequality constraints divergence essentially acting barrier function making sure that stays positive only form lagrangian with moment equality constraints separate lagrange multiplier equality constraint later that will treat differently thus introduce corresponding lagrangian dual function need minimize lagrangian with respect convex just need find zero gradient have this example constraint qualification condition there others lecture november fall that part exponential family distributions dual function plugging this value abused shorthand notation below denote even though necessarily normalized where therefore maximize with respect plugging back eliminating from dual problem ensure that normalized which treated differently corresponding objective remaining dual problem lecture november fall interpret this dual problem link with maximum likelihood exponential family then where then dual problem which same maximal likelihood estimate summarize maximal likelihood exponential family with sufficient statistics equivalent maximal entropy problem with moment constraints where they lagrangian dual another exponential family maximum entropy with moment constraints note moreover that generalized maximum entropy principle minq with instead uniform then exponential family with reference density instead uniform distribution remark model moment therefore where empirical moment note that maximal likelihood parameters exponential family also doing moment matching which expected equivalence above lecture november fall case exponential family have that maximum likelihood equivalent maximum entropy which equivalent moment matching other parametric families mixture models example which exponential family then moment matching could give different estimator than maximum likelihood 
information theory exponential families lecture october lecturer guillaume obozinski scribe thomas belhalfaoui chizat information theory entropy will following properties jensen inequality convex integrable random variable strictly convex have equality only constant definition entropy random variable taking values finite denote information theory quantity interpreted quantity information carried occurrence this sometimes called self information entropy defined expected amount information random variable base logarithm natural base latter being more consistent with coding interpretations entropy this course will natural logarithm kullback leibler divergence definition kullback leibler divergence finite distributions kullback leibler divergence between defined lecture october divergence distance symmetric proposition equality holds only proof there exists such that then otherwise without loss generality assume that everywhere make this assumption rest proof convexity function jensen inequality have since furthermore there equality jensen inequality above which implies that summing this last equality over implies that which turn implies that proposition have following inequalities with equality constant card proof since then which implies that with equality which proves first point then choose then card hence card card definition mutual information random variables joint distri bution with marginal distributions mutual information defined lecture october proposition proof directly follows from fact that implies that which definition independence independent correlated correlated independence first implication comes from fact that then then counter example reverse implication following uniform distribution define random variables then correlated dependent remark reverse only true gaussian random variables relation between minimum kullback leibler divergence maximum likelihood principle definition empirical distribution observations random variable empirical distribution derived from this sample where dirac function null everywhere except where takes value proposition parameterized distribution maximizing likelihood equivalent minimizing divergence pjjp proof pjjp second term equal opposite likelihood hence conclusion lecture october remark should compute because this would rule values that have encountered such that maximum entropy principle maximum entropy principle different principle than maximum likelihood principle solves different kind problem assumes that data specify constraint possible distribution choose idea maximize entropy under constraint that where possible distribution typically specified from data consider following examples study kangaroos estimated that kangaroos left handed drink foster beer what reasonable estimate fraction kangaroos that both left handed drink foster beer maximum entropy principle invoked choose among distributions pairs binary random variables particular formalize that want choose least specific distribution that satisfies these constraints find distribution with maximal entropy that satisfies constraints marginals variable left handed drinks foster beer then problem formalized what solution this problem exercise among distributions what distribution with expected value equal which largest entropy exercise possible show that distribution with fixed mean fixed variance that maximal differential entropy gaussian distribution principle maximum entropy also principle invoked construct distribution angles with fixed mean variance leads called wrapped normal distribution related distribution angle which also maximum entropy distribution mises distribution maximum entropy principle used often when working with contingency tables entropy divergence continuous random variables continuous random variable taking values continuous space probability density function have following adapted expressions entropy divergence lecture october differential entropy hdiff differential kullback leibler divergence ddiff continuous case entropy necessarily negative remark definition hdiff depends reference measure this means that hdiff does capture intrinsic properties more loses physical interpretation terms quantity information least absolute sense contrast ddiff does depend choice reference measure therefore stronger interpretation exponential families observations random variable definition statistic just function data definition sufficient statistic statistique exhaustive french function sufficient statistic model only note that order estimate from data using maximum likelihood principle information statistics carries information that relevant another interpreting what sufficient statistic take bayesian point view bayesian statistics parameter modelled random variable then have which means that definition exponential family random variable exponential family family distribution form where lecture october ancillary statistic reference measure base measure sufficient statistic also called feature vector parameter canonical parameter partition function proposition proof definition canonical exponential family canonical exponential family exponential family which such that definition domain domain exponential family defined example multinomial model random variable follows multinomial distribution parameter this expression easily recognize lecture october counting measure constant function equal recognize find using proposition that first expression likelihood exponential form take into account fact that there hidden constraint have expression more constraint over values that take example gaussian distribution over recognize exponential family with lecture october domain example many other common distributions exponential families binomial poisson dirichlet gamma exponential link with graphical models xixj figure ising model example ising model xixj ijij xixj this first expression overparametrized rewrite expression with just parameter pair ijxixj lecture october example general discrete graphical model general case discrete graphical model such that have where possible values clique recognize minimal representation remark actually does depend only definition common probability zero definition affinely dependent statistics denote sufficient statistics said affinely dependent definition minimal representation exponential family vector sufficient statistics provides minimal representation exponential family these statistics affinely independent theorem every exponential family admits least minimal representation necessarily unique unique minimal dimension remark will quite often redundant minimal representations lecture october exponential family sample consider sample distributed according which belongs exponential family then sufficient statistics where canonical parameter domain remain same single observation partition function general exponential family general exponential family parametrize with function such that open connected subset definition curved exponential family exponential family said curved jacobian full rank example convexity differentiability exponential families lemme lder inequality such that jjxj jjyj where jjxj jpdx jqdx theorem convexity canonical exponential family have following properties lecture october convex subset convex function convex function proof singleton result trivial there exist such that thus convex function moreover which proves that convex taking obtain hence convex function corollary canonical exponential family maximum likelihood estimator solution convex optimization problem proof likelihood concave lecture october remark theorem does hold those cases family curved fully observed consider marginal likelihood observations theorem then proof technical standard show using dominated convergence theorem that exchange differentiation expectation computations differentials then which proves first formula general deduced induction 
approximate inference sampling variational inference fall cours november enseignant guillaume obozinski scribe basile ment nathan lara approximate inference with mcmc gibbs sampling consider undirected graph associated distribution from which want sample order inference example assumed that difficult sample directly from easy sample from idea consists using markov property that jxni where markov blanket node based this gibbs sampling process that converges distribution most classical version gibbs sampling algorithm cyclic scan gibbs sampling algorithm cyclic scan gibbs sampling initialize while while return another version algorithm called random scan gibbs sampling consists picking index random each step cours november fall algorithm random scan gibbs sampling initialize while draw uniformly random while return application ising model consider ising model graph random variable which takes values with probability distribution that depends some parameter ijxixj apply gibbs sampling algorithm need compute xijx have ijxixj xjxj thus ijzxj xjxj taking ratio previous quantities last terms cancel xixj xijx particular xijx ijxj ijxj cours november fall where logistic function without surprise conditional distribution xijx only depends variables that neighbors graph that form markov blanket since must have xijx since conditional distribution given other variable bernoulli easy sample using uniform random variable proposition random scan gibbs sampling satisfies detailed balance gibbs distribution interest distribution graphical model proof consider step random scan gibbs sampling algorithm starting from distribution graphical model idea prove reversibility first prove result index fixed that prove that transition gibbs that only resamples coordinate reversible write xijx conditional distribution xijx gibbs distribution using kronecker symbol defined else have gibbs xijx gibbs detailed balance gibbs valid random scan case index being chosen random uniformly with probability gibbs transition fact gibbs result then obtained taking average over previous derivation thus stationary distribution random scan gibbs transition proposition gibbs transition random cycle regular then defined gibbs sampling algorithm converges distribution gibbs distribution exercise extend gibbs method potts model exercise prove that gibbs transition special case metropolis hastings proposal that always accepted cours november fall variational inference overview goal approximate inference without using sampling indeed algorithms such metropolis hastings gibbs sampling very slow converge besides practice very difficult find good stopping criterion people working mcmc methods find clever tricks speed process hence motivation variational methods consider distribution finite usually very large exponential family with assume that distribution interest that example distribution graphical model that working with goal compute computing this expectation corresponds probabilistic inference general example potts model using notation have xikxjl recall that argmin qjjp where qjjp since associated with parameter where moment parameter course exponential families thus have pjjq this quantity always negative thus maximizing with respect exponential family leads unique value that attains maximum remark possible here express things only terms moment indeed parameterize distribution realizable exponential family there single distribution maximization problem becomes cours november fall where where called marginal polytope possible moments maximum only attained which exactly expectation that needs computed turns that possible show that always concave function that optimization problem above convex optimization problem interesting note that have thus turned probabilistic inference problem which priori required compute expectations that integrals into optimization problem which furthermore convex unfortunately this convex optimization problem hard solve general because solves hard probabilistic inference problem possible escape fact that latter hard this optimization problem thus general intractable this because reasons general graph marginal polytope number faces which exponential tree width graph function extremely complicated write explicitly mean field order approximate optimization problem possible either change distribution moments change definition entropy mean field technique consists choosing that makes variables independent graphical models variables consider collection distributions that make variables independents consider optimization problem which replace note that general that solution cannot exactly order write this optimization problem potts model need write explicitly have seen course exponential families that distribution maximum entropy under moment constraint also when exists distribution maximum likelihood exponential family associated with sufficient statistic this essentially exactly shows that moment there exists member exponential family such that fact rigorous careful about what happens points boundary correct statement that every interior there exists distribution exponential family such that points boundary only corresponding limits distributions exponential family that degenerate like bernoulli distribution with probability example bernoulli family case which themselves family cours november fall moments mean field formulation ijkl xikxji have other hand independence variables lead xikxjl note that constrained make these variables independent would general have moment here form xikxjl ijkl this main place where mean field approximation departs from exact variational formulation entropy mean field formulation independence variables recall that distribution single node that multinomial random variable mean field formulation potts model putting everything together optimization problem written ijkl problem simple express however cannot longer expect that will solve original problem because restricting have restrained forms that moment parameters ijkl xikxjl take particular since general optimal solution mean field formulation does retrieve correct moment parameter approximation will reasonable from sets moments that achievable moments distributions since moments approximated moments closest independent distribution note cours november fall however that mean field approximation much more subtle than ignoring binary potentials model which would naive finding approximation with independent distribution difficulty though that objective function longer concave because products which arise because independence assumption from mean field approximation coordinate descent each algorithm choice solve this kind problem present algorithm consider case ising model which special case potts model with states each variable mean field formulation ising model when working with ising model simple reduce number variables using fact that therefore write mean field optimization problem becomes stationary points each coordinate correspond zeros partial derivatives that where logistic function note that gibbs sampling with probability ijxj this called mean field because sampling replaced approximation where assumed that sample value equal expectation which physicist correspond mean field ferromagnetic ising model finally lets insist that mean field formulation only formulations variational inference there several other ones among which structured mean field expectation propagation loopy belief propagation which reinterpreted solving variational formulation well tree reweighted variational inference 
introduction probabilistic graphical models lecture december lecturer simon lacoste julien scribes gauthier gidel lilian besson note these scribed notes have only been lightly proofread bayesian method introduction vocabulary priori prior likelihood marginal likelihood posteriori posterior caricature bayesian frequentist bayesian optimistic thinks that come with good models obtain method pulling bayesian crank basically high dimensional integral frequentist more pessimistic uses analysis tools bayesian formulation enables introduce priori information process estimation instance imagine that play heads tails bayesian model graphical model associated represented figure figure graphical model biased coin game cours december compute posterior then beta where number question what probability head next frequensist maximum likelihood approach bayesian where posterior distribution then hence prior convex combination prior then notice that quantity whereas underlines importance prior distibution with unknown coin information priori uniform with normal coin distribution with important concentration mass around bayesian ering limited estimator maximum likelihood estimator which gives unique value enough because estimator itself translate inherent uncertainty learning process thus estimator will density posteriori obtained from bayes rule which written continuous notations bayesian speci uncertainty with distributions that form estimator rather than combining estimator with dence intervals bayesian forced produce limited estimator uses expectation underlying quantity under posteriori distribution instance post cours december more details about bayesians subsection annex then need show that variance variance beta then posterior covariance vanishes where true parameter model bernstein mises theorem says that prior puts zero mass around true model then posterior asymptotically concentrate around gaussian revisiting example consider repeating several times experiment above coins picked randomly each ipped times figure figure graphical model biased coin game repeated times frequentist empirical distribution will converge where distribution coins parameter mixture distribution note that independent other hand cours december exchangeable situations exchangeablility random variables exchangeable they have same distribution permutation indices nite exchangeablility nition naturally generalizes nite families indexed random variables exchangeable every nite subfamily exchangeable finetti theorem nitely exchangeable only some space such that care about exchangeable situations variables particular case situation exchangeable variables that practice however when data combined with scalar observations erent components longer independent some cases those components nonetheless exchangeable instance text words shown sequences that exchangeable because syntax forget order words word model then components exchangeable basic principle used model multinomial example mult where that distribution have hence there exists such that that case this frequentist model over bayesian model puts prior which convenient property prior families conjugacy introduced below cours december conjugacy consider family distribution says that conjugate family observation model posterior belongs same family than prior multinomial distribution gives then dirichlet distribution dirichlet distribution conjugate multinomial wikip more details where stands uniform measure simplex then gets uniform distribution gets beta distribution there exists such that gets shape distribution gets unimodal bump cours december multinomial model assume that prior then posterior posterior mean instance with adds smoothing maximum likelihood estimator consider that posterior used prior next observation this sequential approach cours december bayesian linear regression assume that where then observation issue then also choose gaussian prior then posterior also gaussian with following parameters covariance mean where covariance mean same ones ridge regression with bayesian compute predictive distribution jxnew jdata ynewj xnew predictive where predictive xnew nxnew real number comes from noise model second quantity right hand side comes from posterior covariance ynew ynew jxnew cours december model selection introduction consider models with where figure exampleofmodelsectionforn onthel sandm onther maximum likelihood score since have nition interested capacity generalisation model like avoid over tting commonly dealing with that task select size model cross validation here develop furthermore this part present bayes factors which gives main bayes principal selecting models also will show link with penalised version bayesian information criterion which used frequentists correct maximum likelihood which good proprieties issue with selection model issue with selection variables which active topic research there others ways penalising maximum likelihood selecting models distribution real data wish choose between erence models maximising where test sample distributed fact still maximum likelihood principle take expectation data bayesian framework compute marginal probability data given model djmi cours december applying bayes rule compute posteriori probability model djmi mijd bayes factor introduce bayes factors which enables compare models marginal probability data djmi xnjmi decompose itself sequential using xnjx indeed xnjx such djmi xijx bayesian information criterion bayesian score approximated with data distribution when parameter maximum likelihood estimator number parameters model number observations following section outline proof this result case exponential family given cours december laplace method where negligible rest maximum likelihood dual maximum entropy such that however information sher equal thus main reason presenting that theorem prove consistency other words when number observations cient thanks this criterion choose with probability that converges model that satis argmaxm cours december bring quick clari cation about notations used this part model selection please read below notation confusing used example bishop book sloppy from bayesian perspective could treat model choice random variable example there only models thus discrete variable with possible values therefore when were writing quantities like bayes factor really meant mean that were erent random variables which take complicated values someone asked what space seemed very complicated what meant just that index possible models data random variable usual mixing random variables here their possible values same notation like usual confusing better explicit notation distinguish value generic random variable however general could complicated want example could vector hyper parameters prior distributions could also have binary component indicating absence presence edge graphical model does have just index could even continuous objects also have nite dimensional objects example consider latent variable model observed latent variables decides prior over suppose multi ranges over possible distributions over positive vector here quite complicated object this this would parametric setting parametric nite dimensional appendix example model bernoulli variable consider random variables assume that conditionally then they follow bernoulli priors introduce distribution beta whose density where short name beta function gamma function show that symmetric satis choose prior distribution beta distribution cours december posteriori hence thus instead considering unique variable observe sample data joint distribution written introduce then special case beta distribution remind that beta uniform prior bell curve curve cours december mode case write data post that posteriori expectation parameter convex combination maximum likelihood estimator prior expectation converges asymptotically maximum likelihood estimator uniform prior distribution laplace proposed correct frequentist estimator seemed that absence data proposed virtual observation such that absence data estimator equals this correction known laplace correction variance posteriori distribution decrease have chosen sharper distribution around same than frequentist approach dence intervals narrow around estimator when number observations increase playful propriety this well known property gamma function such that write simplify expression cours december shall note analogy with polya model consider balls colour black white when drawing black ball probability event after drawing back ball ball same colour imagine that draw again black ball then probability this event however more general case show recurrence that marginal probability obtaining some sequence colours drawing from polya exactly marginal probability obtaining same result from marginal model obtained integrating priori theta first this show that drawings from polya exchangeable secondly mechanism this type exchangeability useful gibbs sampling same type bayesian models conjugate priors assume that known deduce from that such that that conjugated model exponential model consider canonical parameter canonical parameter cient statistic note that stand beta distribution then cours december since family exponential post results from thus previous equation consequently univariate gaussian with priori thus cours december where thus post post indeed variance decreases with priori inverse gamma form with priori gaussian priori inverse gamma priori please refer chapter course handout jordan polycopi appendix posteriori maximum because with bayes rule posteriori maximum really bayesian rather slight modi cation brought frequentist estimator predictive probability bayesian paradigm probability future observation will estimated predictive probability cours december sequential calculus possible since xnjx vocabulary priori information likelihood posteriori information naive bayes introduction remarque contrary name naive bayes bayesian method consider following problem classi cation here vector descriptors features with goal learn very naive method will trigger combinatorial explosion bayes formula gets naive bayes method consists assuming that features conditionally independent from class hence xijy then bayes formula gives xijy xijy xijy cours december consider case where features take discrete values consequently graphical model contains only discrete random variables then write discrete model exponential family indeed write that dummy functions cient statistics joint distribution model variables where canonical parameters thus write where partition function have rewritten joint distribution model exponential family given that maximum likelihood estimator exponential family where canonical parameters combined also maximum entropy estimator seen previous course provided that statistical moments cient statistics equal their empirical moments thus introduce nikk nikk maximum likelihood estimator must satisfy moment constraints nikk nikk nnik which them completely then write estimators canonical parameters however goal obtain classi cation model that model only conditional probability from approximated generative model applying bayes rule cours december xijy xijy write conditional model exponential family cient statistics canonical parameters equal those generative model seen functions random variable given that could write partition function equal warning maximum likelihood estimator generative model which usually equal maximum likelihood estimator conditional model advantages drawbacks advantages doable line computationally tractable solution drawbacks generative generative models produce good estimator whenever model true statistical words well speci which means that process that generate real data induce distribution equal generative model when model well speci which most common case better discriminative method discriminative method problem that have considered previous section generative model classi cation classes learn discriminatory classi classes possible exponential family have already seen logistic regression classes classi cation study multiclass logistic regression cours december although have built model from erent staring consideration resulting modelling that possible distribution same exponential family than naive bayes model nonetheless tted model discriminatory approach will erent from tted generative approach tting multiclass logistic regression results from maximisation likelihood classes learning given that other words tting obtained computing maximum likelihood estimator conditional model unlike what happens generative model estimator obtained analytical form learning requires solving numerical optimisation problem 
 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe isabela albuquerque probabilistic graphical models goal model multivariate data graph probability theory more illustratively probability statistics probabilistic model answers queries sampling data probability statistics inverse problem lecture september fall applications some illustrative examples hidden markov models applications notation observed random variable represented graphical model shaded node observed random variable represented graphical model empty node graph edges represents possible correlations between random variables graphical models lack edges graph will represent conditional independence assumptions will later important when modeling problem using graphical models random variables represent quantities interest context random vector often just called random variable thus random variable might scalar vector valued example speech recognition sound wave encoding small time window spectral decomposition phoneme xtxt example part speech tagging word part speech word grammatical classification verb this lecture september fall example gene finding sequence nitrogenous base coding coding example control system latent state observation where continuous vectors given control term terms represent noise system they modeled gaussian noise this kalman filter graphical models back part speech tagging example notation observation words represented vocabulary size problem want model which corresponds exponential size state space thus parameters have estimated define probability distribution trick make factorization assumption about distribution each factor seen clique graphical model needs parameters specified have factors this factorization reduce total number parameters from exponentially grows with linearly grows with lecture september fall back problem want compute marginal probability using factorization assumption write applying distributive property product over rewrite equation this organized efficient compute marginal known message passing algorithm term named message denoted following figure illustrates represented arrow passing through graph themes representation represent structured probability distributions related parameterization full table exponential family estimation given data samples learn parameters distribution underlying observations related learning maximum likelihood estimation inference answer questions about data computing conditional distributions marginals efficient computation message passing algorithm 
 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe william chelle disclaimer these notes have only been lightly proofread probability review motivation question probability data science answer probability theory principled framework model uncertainty question where does uncertainty come from answer there several sources intrinsic certain phenomenon quantum mechanics reasoning about future events only partial information about some complex phenomenon throwing dice hard fully observe initial conditions object recognition model mapping from pixels objects incredibly complex notation note that probability theorists graphical models community both notational shorthands meaning notations often inferred from context therefore recall standard notations random variables will noted sometimes usually they will real valued will denote realizations former random variables values take lecture september fall formally define sample space elementary events then random variable measurable mapping then probability distribution mapping where subsets events field such that measurements world possibilities kolmogorov axioms when disjoint therefore probability distribution induces probability distribution image event thus gets probability shorthand actually used shorthand even more ambiguous where example case dice roll consider random variables measures whether dice result even measures whether dice result formally where otherwise indicator function temporarily assumed countable wikipedia field formalism necessary when uncountable which happens soon consider continuous random variable image possible outputs lecture september fall define joint distribution called random vector vector valued random variable with random variable meant generalized sense represent joint distribution table such running example instance also define context joint distribution marginal distribution distribution components random vector rule this rule property deriving from axioms left exercice reader types random variables discrete random variables discrete random variable countable probability distribution fully defined probability mass function this notation shortened even typing only denoting values variable thereby possible that even sense that means means more generally probability distribution fully characterized cumulative distribution function this comma means intersection both events lecture september fall following properties decreasing example cumulative distribution function discrete random variables cumulative distribution function piecewise constant jumps continuous random variables continuous random variable cumulative distribution function absolutely tinuous differentiable almost everywhere said called probability density function random variable where continuous probability density function continuous analog probability mass function discrete random variable with sums becoming integrals hence discrete continuous prob mass function prob density function note continuous case density function greater than sufficiently narrow interval instance uniform distribution otherwise other random variable basics expectation mean expectation random variable continuous case variance variance measure dispersion values around mean lecture september fall independance independant from noted random variables mutually independant conditioning events suppose that define probability given terms sample space that means look subspace where happens that space look subspace where also happens random variables thus normalization constant necessary order real probability distribution definition product rule product rule always true with subtle point that undefined bayes rule bayes rule about inverting conditioning variables bayes rule chain rule successive application product rule always true that chain rule last part simplified using conditional independance asumptions make like case directed graphical models probability theory usually care what happens sets with probability zero free define value want when lecture september fall conditional independance conditionally independant given noted instance with probability that mother carries genetic disease chromosome probability first child carry disease same probability second child that independant given because only status mother impacts directly each child once that known children probabilities carrying disease independant from each other exercise reader prove that when 
 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe philippe brouillard tristan deleu disclaimer these notes have only been lightly proofread parametric models family distributions parametric model family distributions that defined fixed finite number parameters family distributions formally defined follows where possible understood from context depending parameter valid parameters support distribution usually fixed example support distribution modelling coin flip could similarly gamma distribution support notation indicate that random variable distributed known distribution symbol example indicate that random variable distributed bernoulli distribution parameter would write bern this notation shorthand bern where represents bern indicates that refer bernouilli distribution will later class parametric models which basically means that number parameters potentially infinite these models usually from data with number effective parameters growing with size training data using instead would abuse notation since only scalar specific lecture september fall take another example random variable distributed normal distribution with parameters would write that similar that continuous bernoulli distribution bernoulli random variable given follows support distribution space parameters from that expected value variance bernoulli random variable from figure below that variance highest point when intuitively bernoulli distribution models situation where there only possible outcomes either success failure classical example coin flip getting head success will equals this case parameter would probability head binomial distribution binomial distribution defined independent identically distributed bernoulli random variables with parameter formally note that instead also often used parameter bernoulli binomial distribution lecture september fall bern then have that support distribution space parameters given follows term equal number ways successes trials formally this defined follow term notice that product bernoulli random variables since bern expected value variance binomial random variable deduced from bernoulli expected value variance since indep intuitively binomial distribution seen model independent coin flips other distributions poisson distribution often used model count data poisson where mean parameter gaussian distribution most common distribution real numbers denoted where mean variance parameters here implicitly refers lecture september fall gamma distribution often used model positive numbers denoted gamma where shape parameter rate parameter here list other common distributions look them wikipedia laplace cauchy exponential beta dirichlet statistical concepts probability theory used infer generate data from model this well defined problem contrary statistics infer model based observed data this inverse problem that unfortunately defined probability theory model data statistics illustrate difference between probability statistics suppose have model that generate independent coin flips classical probability theory problem would calculate probability heads happening this case model would given without data case statistics would only have observed data heads trials model wouldn accessible classical statistics problem would infer parameters model that explains observed data what bias coin flip this example frequentist bayesian stated earlier statistics problem defined furthermore even meaning probability differ from different philosophical point views major schools thought using different meaning probability have arisen frequentist bayesian traditional frequentist semantic following represents limiting relative frequency observing could repeat infinite number experiments bayesian semantic following encodes agent belief that lecture september fall laws probability characterize rational combine beliefs evidence observations this approach many motivations terms gambling utility decision theory frequentist interpretation probability illustrate view frequentist interpretation will analyze example discrete random variable suppose that then bern which encodes event that takes value suppose repeat experiments large number times bern large numbers have that empirical average will converge expected value also show that empirical average will concentrates tightly around value central limit theorem consider which represents distribution expected value variance average following thus that variance empirical average goes zero showing concentration more precisely have central limit theorem that notice scaling difference large distribution empirical average close gaussian distribution with mean variance bayesian approach bayesian approach very simple philosophically treats uncertain quantities random variables lecture september fall fact encodes knowledge about system beliefs prior probabilistic models then uses laws probabilities bayes rule answers simplest example illustrate bayesian approach result coin flips biased coin believe that since unknown model random variable thus need prior distribution with sample space defined suppose observe result flips then update belief about using bayes rule where posterior belief likelihood observation model prior belief normalization marginal likelihood illustrate bayesian approach suppose that uniform prior doesn encode specific preferences where symbol means that proportional drop term that doesn contain scaling factor beta function defined gamma function defined note that then joint will mixed distribution lecture september fall beta beta distribution defined beta bayesian posterior distribution contains information need predict likelihood event example what probability that next coin flip using marginalization over using chain rule have definition model thus where conditional expectation called posterior mean meaningful bayesian estimator bayes since beta expected value beta beta then bayes estimator bayes compare estimator from frequentist approach that while unbiased bayesian estimator biased asymptotically unbiased furthermore bayesian estimator encodes uncertainty even data contains only head flips estimator gives small probability flip tail this however case with estimator which tends overfit convention lowercase used even random variable because already used parameter space notation statistical estimator based observations value included valid parameters frequentist statistics consider multiple possible estimators bayesian posterior mean moment matching after selecting estimator analyze their statistical properties bias variance consistency 
 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe philippe brouillard tristan deleu maximum likelihood principle given parametric family define likelihood function some observation denoted depending nature corresponding random variable here either probability mass function discrete probability density function continuous likelihood function parameter with observation fixed want find estimate best value parameter that explains observation this estimate called maximum likelihood estimator given argmax this means value parameter that maximizes probability observation function usually though only given single observation samples some distribution with that case likelihood function example binomial model consider family binomial distributions with parameters with given some observation random variable want estimate parameter that best explains this observation with maximum likelihood principle recall that binomial distribution goal maximize likelihood function even though highly linear function make things easier instead maximizing likelihood function directly maximize strictly increasing function lecture september fall since strictly increasing function common choice maximize likelihood function this leads same value argmax argmax using likelihood function could problematic when some parameter that case assigning this value effect maximization later here binomial model have constant that know form maximize first search stationary points likelihood that values such that this necessary condition maximum section stationary points likelihood given likelihood function binomial model also strictly concave thus being stationary point also sufficient condition global maximum section binomial model relative frequency observation which follows intuition furthermore even though general property this estimator unbiased note that maximized without specifying constraint even though required that however here this extra condition little effect optimization since stationary point already interior parameter space latter cases exploit monotonicity conclude that maxima boundaries resp lecture september fall comments optimization general being stationary point necessary condition local maximum when interior parameter space however sufficient stationary point either local maximum local minimum saddle point multivariate case also need check second derivative local maximum flocal maximum stationarypoints previous point only gives local result guarantee that global maximum need know global properties about function example function concave negative convex function then sufficient condition global maximum need careful though with cases where maximum boundary parameter space boundary that case necessarily stationary point meaning that zero similar multivariate case general necessary condition local maximum belongs interior local maximum need check hessian matrix negative definite this multivariate equivalent hessian where hessian also similar results multivariate case know global properties function example function concave then also sufficient condition global maximum verify that multivariate function concave have check hessian matrix negative semi definite whole parameter space multivariate equivalent hessian concave lecture september fall properties does always exist example estimate boundary parameter space boundary open necessarily unique likelihood function could have multiple maxima admissible general example multinomial model suppose that discrete random variable over choices could choose domain this random variable instead convenient encode random vector taking values unit bases this encoding called encoding widely used neural networks literature where coordinate this discrete random vector define family probability distributions with parameter parameter space called probability simplex choices given probability simplex dimensional object because constraint example here dimensional this makes optimization over parameter space more difficult distribution random vector called multinoulli distribution with parameter denoted mult where component multinoulli distribution seen equivalent bernoulli distribution over choices instead consider multinoulli random vectors mult then define random vector mult with distribution called multinomial distribution with parameters analogue binomial distribution over choices similar multinoulli bernoulli given lecture september fall some observation want estimate parameter that best explains this observation with maximum likelihood principle likelihood function where normalization constant where number times observe value note that remains function observation although this explicit dependence omitted here equivalently could have looked multinoulli model with parameter with observations instead multinomial model with single observation only effect here would lack normalization constant likelihood function like section take likelihood function make optimization simpler constant want maximize such that still valid element given constraints induced probability simplex this involves solving following constrained optimization problem subject solve this optimization problem have options could reparametrize with with constraint likelihood function maximize would become advantage here would that parameter space would full dimensional object sometimes called corner cube which more suitable setup optimization particular could apply techniques from section lecture september fall dimensional optimize here full dimensional choose lagrange multipliers approach lagrange multipliers method used solve constrained optimization problems with equality constraints more generally with inequality constraints well form here apply optimization problem maximization under equality constraint fundamental part lagrange multipliers method auxiliary function called lagrangian function this combination function maximize here equality constraint function where called lagrange multiplier dropped constant since effect optimization search stationary points lagrangian pairs satisfying note that second equality equivalent equality constraint optimization problem first equality leads here lagrange multiplier acts scaling constant required satisfy constraint evaluate this scaling factor lecture september fall once again order check that indeed local maximum would also have verify that hessian likelihood negative definite however here concave function hessian this means according section that being stationary point sufficient condition global maximum multinomial model similar binomial model from section relative frequency observation vector again follows intuition note that which also constraints geometric interpretation lagrange multipliers method lagrange multipliers method applied solve constrained optimization problems form with this generic formulation lagrangian with lagrange multiplier order find optimum search stationary points lagrangian pairs such that latter equality always equivalent constraint whereas former rewritten stationary point lagrange multiplier scaling factor between gradient vectors geometrically this means that these vectors parallel levelsetsoff 
 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe bastien lachapelle disclaimer these notes have only been lightly proofread statistical decision theory formal setup statistical decision theory formal setup analyze decision rules context uncertainty standard problem statistics estimation hypothesis testing will that also supervised learning problem from machine learning though people less used this machine learning random observation would training dataset which used sample space possible values that where distribution over suppose that belongs certain distribution sometimes have that distribution parametrized parameter which case note this distribution represents unknown state world there source uncertainty possible actions will denote certain action statistical loss function loss doing action when actual distribution when world decision rule less formally observe something from nature actually know mother nature generates observations know even suppose that belongs certain distribution context where have choose action among certain actions given facts that choose action that actual reality must certain cost since observe realisation makes sense base action this observation this decision process described important subtle point often will describe process xnqwhere siid this case often just write dependence loss terms instead full joint note that framework also works lecture september fall data this lecture only consider data when write mean distribution joint examples estimation suppose belongs parametrized family distribution call that belongs parameter space denoted pose this context estimator pose following loss function famous squared loss sometimes note instead where this simplification applies remember that this specific case write suppose more specifically that where siid this mean would have pdqq pdqk concrete example suppose that belongs gaussian family would mean that example could choose decision function hypothesis testing where might mean rejecting null hypothesis might mean accepting this context describes statistical test machine learning prediction ynqq have that that call input space output space siid then where joint over couples functions maps prediction setting define prediction loss function this function usually measure distance between given prediction associated ground truth actual loss function would like minimize rlpy fpxqqs this traditionally called generalization error also often called risk machine learning simon calls vapnik risk distinguish from frequentist risk from statistics that will define later this context decision rule actually learning algorithm that outputs function equivalently write that lecture september fall procedure analysis given this framework compare different rules procedures given know which better given application frequentist risk first property analyze procedure called risk frequentist risk edsp rlpp pdqs remarks risk function know what practice never really know what value this function given rule other hand this property theoretical analysis device make statement like some family procedure lower risk than procedure thus better some sense also important distinguish frequentist risk from generalization error vapnik risk next graph expose risk profiles rules simplicity suppose that parametrized distribution that this picture illustrates fact that sometimes there clear winner when comparing rules this case seems that best choice values near values from best choice problem know value know best rule pick will later that there fact ways bypass this problem domination admissibility that decision rule dominates another decision rule given loss function that decision rule admissible dominates lecture september fall theory aside point your culture alternative frequentist risk approach approach which common machine learning theory stands probably approximately correct instead looking average loss over datasets like frequentist risk does looks tail bound loss bound such that know that loss will smaller than with high probability this called given certain loss function decision function distribution over possible small real number theory seeks find bound such that prtlpp pdqq note that could have write instead emphasize fact that this bound depends next graph shows density pdqq given remember that pdqq random variable since random variable allow compare frequentist risk mean approach approach tail bound comparing decision rules would like able compare rules together figure which choose could find rule that dominates other rules would choose this rule often find such rule this there universally best procedure frequentist approach analyze different properties decision rules user then choose which they prefer according which properties better them present standard ways statistics reduce risk profile curve scalar then compare rules together notion optimality minimax criteria following this criteria optimal rule given minimax words minimax optimal rule rule minimizes risk would obtain worst possible scenario lecture september fall weighting this criteria requires that define weighting over interpreted prior formally weight intuitively when considering certain rule averaging risk over possible putting more weight believe more important phenomenon that studying after that compare them with each other pick rule corresponding lowest average bayesian statistical decision theory last criteria were making fact that observed data that observed realization bayesian optimality criteria makes this information before defining this criteria define what call bayesian posterior risk where posterior given prior optimal rule following bayesian criteria bayespdq recall bayesian philosophy treat uncertain quantities with probabilities posterior summarizes information need about uncertain quantity bayesian statistical loss then tells optimally simply need find action that minimizes bayesian posterior risk integrated there more uncertainty about thus only bayes procedure bayesian life quite easy bayesian need worry about other properties like minimax frequentist risk bayesian does care about what could happen other only cares that given specific observation want know given frequentist still decide analyze bayesian procedure from frequentist risk perspective particular show that most bayesian procedures admissible unlike also show that bayesian procedure optimal procedure when using weighted risk summary with weight function which matches prior this seen simple application fubini theorem from diamond graph below lecture september fall where stands conditional where where denotes posterior bayesian procedure property that minimizes weighted summary exercise given show that bayespdq posterior mean examples estimators maximum likelihood estimator mlepdq where likelihood function given observation maximum posteriori where posterior distribution over possible method moments suppose have that with siid being scalar random variables where vector idea find bijective function that maps vector moments mkpx perx basically mkpx qsince bijective invert pmkpx intuition that approximate could evaluate function using input empirical moments vector mkpx perx where erxj given this would method moments estimator lecture september fall example suppose that siid have that this defines function invert relation then finally replace moments empirical moments estimator here this estimator same estimator this illustrates property exponential family will this later this class note method moment quite useful latent variable models mixture gaussian spectral methods tensor decomposition methods recent literature prediction function estimation this context decision rule function called hypothesis space looking function that minimizes generalization error formally edsp rlpy fpxqqs fpyx since know what compute edsp rlpy fpxqqs replacement consider estimator erlpy fpxqqs where rlpy fpxqqs lpyi fpxiqq stands empirical risk minimizer here vapnik risk tensor decompositions learning latent variable models anandkumar jmlr lecture september fall convergence random variables convergence distribution general that sequence random variable txnun converges distribution towards random variable fnpxq fpxq where correspond cumulative functions respectively such case note convergence general that sequence random variable txnun converges norm towards random variable xkkks such case note convergence probability general that sequence random variable txnun converges probability towards random variable tkxn such case note note turns that convergence implies convergence probability reverse implication true properties estimator suppose that that siid will note npdnq estimator subscript stands emphasize fact that estimator value depends number observation bias estimator biasp lecture september fall standard statistical consistency that estimator consistent parameter converges probability toward consistency that estimator consistent parameter converges norm toward bias variance decomposition consider will express frequentist risk function bias variance remark other loss functions would have potentially different function bias edsp biasp variance thus expressing different priority between bias variance james stein estimator james stein estimator estimating mean siid dominates estimator squared loss when thus showing that lecture september fall inadmissible this case turns that james stein estimator biased that variance sufficiently smaller than variance offset bias properties assuming sufficient regularity conditions have consistent where fisher information matrix asymptotic optimality among unbiased estimator scalar parameter with lowest variance asymptotically this results follows from cram bound result which stated like this unbiased estimator scalar parameter then have that note that this result also stated multivariate case invariance reparametrization suppose have bijection then mleq this result generalized case where bijection suppose bijective define profile likelihood ppdata also define generalized this case then have that mleq this called plug estimator because simply plugging value function examples pmle mleq psin qmle sinp mleq 
 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe zakaria soliman disclaimer these notes have only been lightly proofread linear regression motivation want learn prediction function where binary classification multiclass classification regression problem there several perspectives modeling distribution data generative perspective here model joint distribution make more assumptions this case this leads less robust predictions more flexible approach sure what task trying solve conditional perspective only model conditional probability early called discriminative perspective simon prefers refer conditional approach fully discriminative perspective models directly estimate function using loss information this approach most robust linear regression model take conditional approach regression assume that depends linearly linear regression model following form lecture september fall where parameter weight vector equivalently could also rewrite model where noise random variable that independent remark note that there offset that will offset notation where constant feature thus have where bias offset training conditionally random variables whatever each response observation consider conditional likelihood outputs given inputs indep have that taking likelihood gives following expression notice that maximizing likelihood comes down following minimization problem find minw define design matrix lecture september fall denote vector coordinates this notation allows rewrite residual squares more compact fashion thus rewrite likelihood finally minimization problem over rewritten find minw remark minimization also viewed geometrically choosing that vector orthogonal projection onto column space find using normal equation invertible there unique solution then full rank invertible this case could pseudo inverse choose minimum norm solution amongst minw problem face that pseudo inverse numerically stable latter case would better regularization techniques next section lecture september fall ridge regression either interpret ridge regression adding norm regularizer least square replacing with adding prior where prior over have that then notice that always invertible remark strongly convex there unique global minimum remark good practice standardize normalize features standardizing means make features have empirical zero mean unit standard deviation normalizing mean different things scale them unit norm logistic regression turn attention classification problems this model will assume that make additional assumptions apart that densities goal model lecture september fall figure sigmoid function where class conditional ratio prior ratio odds ratio general have where sigmoid function shown figure lecture september fall sigmoid function following properties property property example finally make following observation that very large class probabilistic models yield logistic regression types models thus explaining logistic regression fairly robust consider that class conditional exponential family where thus have logistic regression model with features 
 probabilistic graphical models fall lecture september lecturer simon lacoste julien scribe eeshan gunesh dhekane younes driouiche disclaimer these notes have only been lightly proofread logistic regression about logistic regression turn attention binary classification problem define problem learning from input data usually subset some labels usually denoted there major approaches classification problem generative discriminative generative approach models distribution input data along with distribution labels given input data discriminative approach other hand models only distribution labels given input data logistic regression discriminative approach problem binary classification this approach only model learn required distributions where represent random vectors corresponding input data corresponding labels respectively despite this simplicity modeling problem logistic regression robust approach this because many other models share form with that this model begin discussion logistic regression with mathematical formulation formulation denote random vector that corresponds input data assume that some denote random variable corresponding labels input data binary classification problem assign values labels thus have goal model learn which distribution labels given input data model distributions functions form distributions chosen sigmoid function linear transformation will reasons later thus have where parameter model this form gives expression target distribution bernoulli lecture september fall denote given dataset with then goal learning becomes problem learning from given dataset which will consider through next sections generative motivation optional stated earlier that logistic regression fairly robust approach also defined function particular form this subsection provide generative motivation that tries justify these statements definitions this make major assumptions except existence probability density functions these distributions called class conditional distributions starting with class conditional distributions goal obtain following manner thus from previous equation where sigmoid function here odds ratio defined follows class conditional ratio prior odds ratio note that major proportion common distributions used modeling special cases exponential family distributions will study this later course distribution specified functions defined given below linear cannonical parameter pexp sufficient statistics partition function pexp then write from terms weight vector feature with lecture september fall thus generative model with class conditionals exponential family yield which precisely logistic regression model with feature concrete example exercise reader with multivariate gaussians exponential family then have that this linear regression model otherwise different covariances different classes then also assignment note that does appear definition even though does influence distribution given class conditional this means that there many different generative models which gives same model thus logistic regression model robust changes these choices which what meant saying that logistic regression more robust model than generative model approach sigmoid function properties this section provide quick review some properties sigmoid function formally defined follows figure shows graph sigmoid function over figure sigmoid function below some important properties sigmoid function prove using exercise lecture september fall property property property limz limz maximum conditional likelihood recap from subsection formulation have following model thus bernoulli equivalently maximum conditional likelihood from subsection formulation also that problem modeling becomes problem learning from dataset will method maximum conditional likelihood estimate parameter model given dataset conditional likelihood order solve first need find stationary points where have towards this define follows then have evaluate follows thus required expression lecture september fall solving turns that what known transcendental equation such equations often hard solve have closed form solutions thus left with choice using numerical methods find maximum conditional likelihood estimate next section provides description some useful numerical methods remark consider then encode both cases equation follows remark contrast transcendental equation obtained logistic expression approach obtained linear equation case least square regression approach recall that obtained hence solving setting essentially solving linear equation numerical optimization start with function defined some variable over domain want solve problem minimizing over this domain minimize over minw case thus domain gradient descent order method motivation motivation this approach fact that gradient function points direction maximum increase function thus order minimize function natural decision follow direction maximum decrease function this achieved traveling direction opposite that gradient algorithm gradient descent algorithm described below initialize update iterate converged update step lecture september fall here size step iteration hyperparameter needs chosen appropriately note that very small value then convergence very slow however very large value then algorithm converge diverge instance thus need have conditions heuristics choose properly some step size rules heuristics step size constant this constant chosen equal where lipschitz constant lipschitz constant vector function smallest number such that domain function have decreasing step size rule where constant heuristic behind this that want able cover domain achieved having however also want deviate away that converge solution achieved having choose solving where direction update this method called line search however since this approach general costly approximate search newton method order method motivation here approximate given function terms quadratic approximation relatively easy optimize quadratic function rather than given function which might have desirable convex concave nature taylor expansion given function obtain quadratic approximation follows taylor remainder quadratic approximation where here hessian function quadratic approximation function update formula obtained minimizing this quadratic approximation rwqt example have armijo line search conditions more details please refer book convex optimization stephen boyd lieven vandenberghe lecture september fall damped newton method order stabilize newton method incorporate step size update step given follows algorithm algorithm damped newton method given below initialize update iterate until some condition update step advantages disadvantages convergence newton method usually gives much faster convergence terms number iterations compared gradient descent method however each iteration newton method more costly than that gradient descent method specifically gradient descent update takes time space because need manipulate dimensional vectors gradients however newton method involves calculation inverse hessian which requires space takes time thus there trade number iterations till convergence versus complexity each iteration affine invariance role newton method affine invariant which means that invariant scaling variables reason behind this that update term newton method inverse hessian which transforms space make well conditioned demonstrate intuitive benefits this property effect presence hessian inverse following optional subsection role optional consider very simple example where have function minimize given where denotes component minimize this function using gradient descent newton method compute gradient hessian lecture september fall gradient descent newton method since hessian inverse proportional identity matrix gradient descent newton method have essentially same update steps except constants further update terms proportional thus updates from both directly along direction from global minimum however parameterize using thus same function function with compute gradient hessian follows gradient descent newton method that gradient descent proportional because hence direction update ideal because does point towards global minimum this effect parameterization however note that presence makes update term newton method proportional this makes direction update once again point towards global minimum thus that newton method affine invariant presence hessian inverse update step figures illustrate comparison gradient descent updates newton method updates elliptic loss function circular loss function respectively irls iterative reweighted least square formulation newton method applied logistic regression often called irls newton method solve transcendental equation encountered earlier recall lecture september fall figure elliptic loss function newton method updates point ideal direction whereas gradient descent updates this demonstrates role played inverse hessian newton method updates figure gradient descent updates newton method updates essentially identical except scaling constant given initialization parameter they both point ideal direction coincident lecture september fall from that given vector then xixi negative semi definite concave newton updates would indeed maximize likelihood design matrix where have input data label corresponding then expressed here diagonal matrix defined based this notation newton method updates given follows dtzt here defined follows this definition along with update step expression from indicate that each time step essentially solving weighted least square problem this seen follows lecture september fall square matrix matrix square root diagonal entries since diagonal thus have xxxxxxthen ttttt leastsquaresestimation from previousequationandthe frompreviousclass design matrix defined design matrix defined minw minw minw thus solution above weighted least squares problem form which represents gaussian noise model thus takes form data dependent noise logistic regression data data constraints logistic regression term data often stands datasets with large number data points large value each element being vector high dimensional space large value with data there several constraints methods used model dataset using logistic regression have seen that second order newton method incurs time space computation inverse hessian case data large number thus cannot afford these order computation thus must resort first order methods have also seen that first order method gradient descent faster iterations however number iterations till convergence large thus need improve upon gradient descent method batch gradient descent consider called batch gradient descent update step which described follows lecture september fall update where represents gradient input feature however computation each iteration involves computations gradients features thus overall computations iteration which afforded thus batch gradient descent data thus resort stochastic gradient descent variants extensions discuss some representative methods following subsections stochastic gradient descent update step involves randomly picking input feature iteration plugging gradient descent formula gradient that feature formally update formula given update randomly pick iteration time instance evaluate gradient rfit input feature indexed update follows rfit this approach cheaper complexity computations performed each iteration however convergence this method very poor when compared against batch gradient descent method also very high variance this intuitively seen follows there certain inputs which gradient takes abnormally large values then update step will sway from ideal update direction huge amounts this good convergence since such samples will easily mislead updates some extent cater high variance using stochastic mini batch gradient descent here instead evaluating gradient single randomly picked feature evaluate averaged gradient over randomly selected batch features with indices update step described below update randomly pick indices iteration evaluate averaged gradient rfij update follows lecture september fall updates incur computations iteration appropriate choice afford these updates intuitively averaging gradients diminishes effects abnormally large gradients update which slightly improves decreases variance note that convergence analysis mini batch shows that there advantage mini batch size bigger than cost mini batch step times cost gradient reason that variance decreases when increases yielding smaller total number iterations reach specific accuracy however this reduction number iterations smaller than thus each step times more expansive there overall gain using mini batch main computational reason mini batch when access parallel processing with parallel processors computation gradients made almost fast that only gradient this yields overall speed note that example approaches called incremental gradient methods optimization last years methods called variance reduced incremental gradient methods were proposed further speed these methods their idea reduce variance using memory present first these which breakthrough optimization literature stochastic averaged gradient small tweak called saga stochastic averaged gradient saga idea memory previous computations calculate update term update update here called memory variables every iteration update only memory variables rfit some randomly picked keep previously memory variables unchanged simply their computed values from previous iterations this method incrementally computing approximated gradient decreases variance method considerably particular allows constant step size like gradient descent which convergence much better than disadvantage that expectation over random choice update direction equal biased because that convergence proof very complicated with tens pages with numerically found quantities saga method small change make update direction unbiased significantly simplifying convergence proofs lines update step saga paper minimizing finite sums with stochastic average gradient lagrange prize mathematical programming lecture september fall update rfit variance reducingcorrection that variance reducing correction term zero expectation over thus yielding unbiased update direction expectation saga default method optimizing logistic regression scikit learn library figure summarizes characteristics methods discussed above figure comparison batch gradient method deterministic stochastic gradient method method stochastic saga hybrid methods method converges faster each update costly method cheap updates converges slowly hybrid methods best both worlds these methods achieve faster convergence with cheap updates further above notes were just quick introduction topic these methods covered greater details class advanced structured prediction optimization scikit learn standard libraries python based machine learning more information saga please refer original nips paper saga fast incremental gradient method with support strongly convex composite objectives 
 probabilistic graphical models fall lecture october lecturer simon lacoste julien scribe eeshan gunesh dhekane disclaimer these notes have only been lightly proofread fisher linear discriminant analysis consider problem binary classification last class considered logistic regression which discriminative conditional approach binary classification this class consider linear discriminant analysis which generative approach binary classification recall that conditional approach models only predictive distribution labels given input data other hand generative approach models input data well specifically models entire dataset distribution through gaussian class conditional distributions bernoulli prior distribution parameters involved this modeling easily learned from training dataset using closed form maximum likelihood estimates having learned parameters predictions easily made test dataset through predictive distribution following sections will consider approach detail however begin with brief introduction vector matrix calculus followed plate notation graphical representation probabilistic approaches vector matrix calculus motivation recall that definition derivative real valued function real valued variable given follows function said differentiable limh exists finite value value limit limh often denoted called derivative notion derivative function extremely useful modeling rate change points extrema linear approximation thus want extend note that linear discriminative analysis generalizes fisher linear discriminant method which uses linear combination features data classification simplicity will denote fisher linear discriminative analysis throughout notes lecture october fall this notion broader class functions specifically want define derivative vector matrix valued functions vector matrix argument clear from that same definition used directly generalization because involves limit fraction vectors matrices notion fraction division always well defined however rewrite follows limh equivalent where error function that satisfies limh this form definition derivative easier generalize desired broader category functions involves writing change value function asthe linear operator acting change argument function error function note that linear operator defined entirely terms acts change argument also error function must satisfy limh with these observations generalize definition derivative generalizing differentiability first consider vector valued functions vectors definition differentiability consider function such that differentiable linear operator such that here represents error function such that limk term usually called read little linear operator called differential differential linear operator remark differential operator thought machine processor which inputs vectors from processes them generates output vector should noted that this operator entirely defined terms should linear operator thought machine that inputs variable from domain space processes yields output target space will briefly consider exact meaning operator next subsection however will describe form these operators specific cases interest lecture october fall remark case differential takes form matrix with order operation becomes matrix multiplication details given below then differential represented matrix order called jacobian matrix denote component then where component component remark this definition differentiability differential from gives define derivatives only cases vectors also matrices tensors easy that exactly same definition will continue hold more general cases matrices tensors however needs careful about form differential remark another important case consider that real valued functions square matrices important required estimations corresponding gaussian distributions case differential takes form matrix with order operation becomes trace matrix multiplication details given below then chain rule most important frequently used formula evaluation differentials composition function chain rule expresses differential composition functions terms differentials individual functions follows then term product jacobians remark easy extend chain rule composition more than functions exercise also note that resultant product jacobians will always well defined lecture october fall important examples this subsection consider some examples that only help demonstrate definition from order calculate differentials certain important functions build required tool analysis subsequent sections differential squared mahalanobis distance such that have where constant vector order evaluate differential consider following manipulations where dimensional zero vector clearly limkhk thus definition have where dimensional identity matrix consider such that have where fixed matrix order order find differential consider following manipulations also easy prove that limkhk this exercise thus definition have consider matrix inverse covariance matrix some gaussian distribution with then squared mahalanobis distance with respect given gaussian distribution denoted defined follows note that term appears likelihood expressions involving gaussian distributions hence need evaluate differential order solve estimates consider following manipulations getting required differential extra information please refer wikipedia page mahalanobis distance lecture october fall define such that have where denotes function composition here functions defined above thus differential computed using chain rule follows since symmetric have thus remark calculation differential must ensure that error function denoted tends strictly faster than almost cases will deal with vector matrix tensor values thus default will consider frobenius norm matrix including vector defined follows frobenius norm vector matrix denoted ktkf frobenius norm vector defined kvkf frobenius norm matrix defined kmkf differential determinant square matrix another important function that appears whenever consider likelihood involving gaussian distributions logarithm determinant covariance matrix thus important consider differential determinant matrix function defined consider matrix then simplicity restrict proof symmetric matrix that strictly positive definite this implies that invertible that matrix square roots exists spectral theorem such that denote call square root matrix note that always find square root real valued symmetric matrix hence proof will work cases when equals covariance matrix gaussian distribution inverse matrix denote eigenvalues decreasing order with multiplicity counted then will extra information frobenius norm please refer wikipedia pages matrix norm frobenius inner product more information square roots matrices their existence construction please refer wikipedia page square root matrix lecture october fall following standard linear algebra properties derivation matrices have matrix that diagonalizable have matrices have matrix have xxxx consider derivation obtain differential determinant thus definition differential determinant using standard notation have remark optional proof above small jump after expanding terms error function terms where need prove that limk prove this follows observe that eigenvalues thus square matrix dkbkf second last inequality follows from root mean squares inequality matrices cauchy schwarz inequality gives called root mean squares inequality forms special case broad category important inequalities involving generalized mean concise reference these inequalities found wikipedia page generalized means inequality lecture october fall this gives required limit every using squeeze theorem limits have since from derivation have limk limk thus limk this completes proof that error function indeed tends zero strictly faster than simply replace ugly expression error function references details related matrix calculus please refer book matrix differential calculus with applications statistics econometrics neudecker magnus plate notation graphical representation motivation before begin with analysis take look method graphical representation probabilistic approaches called plate notation here represent probabilistic approach graphical format that easy visualize picture worth thousand words probabilistic model want model uncertainty some random variables vectors parameters then learn corresponding underlying distributions assume that rest random variables vectors parameters fully known hence want model uncertainty these variables graphical model need rules represent these different sets variables clearly further dependencies between various random variables parameters under consideration should clearly represented addition might happen that scenario huge number random variables parameters that need considered dataset with samples then need represent repeated variables diagram concise well precise manner towards this consider following rules define graphical representation method note that there multiple conventions setting dimensions derivatives imperative that stick particular convention order consistent results definition from results answers that abide called numerator layout this context good reference point checking final answers expressions derivatives wikipedia page matrix calculus more information please refer wikipedia page plate notation note that rules graphical representation probabilistic models vary from different sources wikipedia reference plate notation gives such sets rules graphical representation lecture october fall rules graphical representation plate notation random variables parameters which want model uncertainty represented circular nodes with variable names random variables parameters that assumed known which model uncertainty represented square blocks with variable names dependencies between various random variables parameters represented using directed arrows random variable observed then circular node corresponding shaded observed then circular node corresponding shaded note that rules above help convention graphical representation probabilistic approaches however need cater cases where variables repeat called plate notation help conventions concisely representing repeated variables model rectangle also called plate group together inside random variables parameters that repeat together each variables plate indexed range index mentioned plate order expand representation repeated contents plate arrows that cross plate represent directed arrow repetition plate figure illustrates these rules with help example figure example graphical representation involving plate notation note that parameter assumed known uncertainty modeled there random variables which want model uncertainty dependent only random variables dependent parameter only observed variables observed note that figure left represents this model concisely using rules graphical representation plate notation equivalent expanded graphical representation shown right lecture october fall analyis formulation consider analysis generative model binary classification denote random vector corresponding input data such that denote random variable corresponding binary label input represent labels thus model input data modeling entire dataset terms class conditional distributions prior distribution assume following forms distributions bernoulli some here mean class represents covariance matrix with notice that assumes that covariance matrix same both classes class class figure schematics scenario which best modeled note that class conditional distributions have different means same covariance matrix input dataset then problem modeling dataset becomes problem estimating parameters that define class conditional prior distributions will joint maximum likelihood estimation estimate these desired parameters lecture october fall maximum likelihood estimation optional formulate maximum likelihood problem follows likelihood datapoint thus likelihood each datapoints thus likelihood entire dataset optimize find stationary points with respect parameters will results differentials important functions evaluating formulae number datapoints with label equal thus lecture october fall with post multiplying gives thus derivation needs some manipulations standard properties needed this listed below will also expression differential determinant scalar trace thus provided products well defined thus thus symmetric thus reparametrizable will evaluate rather than easier since thus thus thus lecture october fall remark note that still remains proved that these estimates indeed maximize objective exercise details related optimization numerical computation please refer convex optimization boyd venderberghe deep learning book goodfellow bengio courville predictive distribution inference optional having modeled entire dataset estimating required parameters next step apply this model predict class test data this inference carried using predictive distribution follows test point predicted label otherwise thus need find expression which below thus from previous equation where sigmoid function here odds ratio also called scoring function defined follows class conditional ratio prior odds ratio from have lecture october fall also have observe that scalars further because thus from with thus where with remark note linear decision boundary covariances been different decision boundary would have been quadratic curve conic section remark note that fisher models generative approach models whereas logistic regression discriminative approach models both approaches predictive inference rule based evaulating test input lecture october fall lecture october fall previous exercise shows that despite difference approaches predictive inference rule fisher logistic regression have essentially same form form logistic regression where some further incorporate bias constant logistic regression make scoring function generalized linear scoring function easy that thus replace with equivalent generalized logistic regression thus that generalized logistic regression fisher both have same inference rule sigmoid linear function datapoint also inference rule basic logistic regression fisher essentially same except bias term scoring function remark graphical representation given done figure where exercise find graphical representations linear logistic regression approaches figure graphical representation using plate notation unsupervised learning views unlabeled data till have consider scenarios modeling datasets input data points corresponding labels however there numerous real life problem settings where have access labels corresponding data thus without labels want model data there ways consider unlabeled data mixture distribution approach latent variable approach order understand these approaches better consider example unlabeled data figure given data viewed mixture several component distributions instance data distribution figure viewed mixture gaussian lecture october fall cluster cluster figure there views unlabeled data view mixture distribution consider data terms latent variables example appears though data coming from different groups clusters hence finding characteristics these structures order learn underlying structure distribution however easily visualize data coming from groups clusters such that points from same cluster very similar another those from different different from another thus understand structure data better manner trying model these clusters however since cluster assignment data points available unsupervised problem call clusters latent variables learn latent variables from available data difference approaches also seen from their plate diagrams which given figure this scribe will only consider latent variable approach figure graphical models mixture distribution approach left latent variable approach right here represents unlabeled data represents assumed latent variables corresponding data point lecture october fall means algorithm motivation consider problem clustering given unlabeled data want learn cluster assignment function that predicts cluster which each data point mapped assume that there clusters data which labeled represent each clusters representative cluster center idea that data points that belong particular cluster center should differ much from corresponding cluster center measure this extent difference using distortion function which defined terms chosen distance function since have information about cluster centers initialize them randomly then perform iterative algorithm starting with guess cluster assignment function which maps each data point some cluster center then update cluster centers that distortion measure minimized intuitively this step makes guess cluster centers better however with better guess cluster centers better cluster assignment function thus repeat these steps decrease distortion function until converge best cluster centers cluster assignment function formulation will following notations observations want partition means where center cluster will denote associated matrix indicator variables associated such that belongs cluster otherwise matrix which components equal distortion function define distortion kkxi algorithm algorithm minimize proceed with alternating minimization block coordinate minimization initialize cluster centers minimize with respect mins other words associate nearest center minimize with respect come back step until convergence remark step minimization with respect equivalent allocating voronoi cells which centers remark during step minimization with respect obtained setting zero coordinate gradient with respect indeed easily that lecture october fall properties means converges finite number iterations local minimum however just local general hard find best cluster assignment general implies that there cases which require time exponential input size there certain cases where there very easy solutions very fast requires lesser number iterations initialization very important means there algorithm means which gives clever initialization scheme that guarantees that objective within global optimum with high probability there theoretical guarantee spread initial mean points much possible this avoids wrong clustering image class select means inverse their distance from previous means choice heuristics regularization term hyperparameter need experiment with value later class will parameteric models where basically infinite data example dirichlet process mixture model effect optimal value means very sensitive distance measure used when using getting spherical clusters also choice clustering depends problem itself different objectives will have different best choices clustering which will decided different distance measures figure class clustering actually good clustering mail problem problem previous figure fixed gaussian mixture model convergence initialization show that this algorithm converges finite number iterations therefore convergence could local thus introduces problem initialization classic method random restarts consists choosing several random vectors computing algorithm each case finally keeping partition which minimizes distortion thus hope that least local minimum close enough global minimum other well known method means algorithm which aims correcting major theoretic shortcomings means algorithm approximation found arbitrarily with respect objective function compared optimal clustering means algorithm addresses this obstacles specifying procedure initialize cluster centers before proceeding with standard means optimization iterations with means initialization algorithm guaranteed find solution lecture october fall that competitive optimal means solution intuition behind this approach that clever thing well spread initial cluster centers each iteration algorithm will build center will repeat algorithm until have centers here steps algorithm first initiate algorithm choosing first center uniformly random among data points each data point your data compute distance between nearest center that already been chosen denote this distance where specified recall that minimizing over current chosen centers choose data point random center using weighted probability distribution where point chosen with probability proportional repeat step step until centers have been chosen that have built vectors with respect first intuition which well spread centers because used well chosen weighted probability those vectors initialization standard means algorithm more details found means algorithm arthur vassilvitskii means advantages careful seeding proceedings eighteenth annual siam symposium discrete algorithms 
 probabilistic graphical models fall lecture october lecturer simon lacoste julien scribe martin weiss eeshan gunesh dhekane disclaimer these notes have only been lightly proofread graph theory review directed graph definition directed graph consists nodes vertices edges such that ordered pairs distinct vertices will only consider graphs that have self loops figure directed graph with definition directed path from vertex vertex directed graph consists ordered sequence vertices where such that denote this directed path from squiggly arrow equivalently directed path also viewed sequence edges mentioned above same path represented ordered sequence edges example given below shows directed path from figure definition parents vertex denoted vertices from which there edge analogously children vertex denoted vertices which there edge from figure below shows parent which children which lecture october fall figure directed path from with vertices edges figure parent children undirected graph definition undirected graph consists nodes vertices edges such that sets without self loops thus edge identical edge since there self loops edge have figure shows example undirected graph figure undirected graph definition undirected path from vertex vertex directed path consists ordered sequence vertices where such that equivalently undirected path also viewed sequence edges mentioned above example given below shows directed path from figure lecture october fall figure undirected path from definition neighbors vertex denoted vertices that connected with through edge undirected graph neighbors replace notions sets parent children figure shows neighbors vertex figure vertex with neighbors directed acyclic graph definition cycle directed undirected graph consists ordered sequence nodes such that there exists directed undirected edge from there exists directed undirected edge from equivalently there exists directed undirected path from some vertex examples directed undirected graphs above there cycle directed graph however there cycle undirected graph namely definition directed graph with cycles called directed acyclic graph note that directed graph considered indeed directed acyclic graph definition ordering vertex directed graph said topological only bijective implies that lecture october fall what this deinition implies that order increasing manner vertices based topological ordering will always have parent node appearing before node itself directed arrows would point right leaving back edges observe that from figure ordering vertices already topological ordering which displayed figure figure example topological ordering from figure theorem characterization dags using topological ordering directed graph topological ordering proof given perform depth first search algorithm number descending order nodes which children while performing because there cycle will always find nodes with children during this algorithm thus this generate topological ordering time trivial there topological ordering then have back edges hence have cycles thus notation graphical models given random variables assume that discrete random variables simplicity this part class this because defining conditional distribution continuous random variables challenging please refer borel kolmogorov paradox challenges defining conditional distributions given graph such that associate random variable node letting random variable associate with node subset vertices defined easy that where denotes summing over possible values instance represents joint probability given lecture october fall about graphical models graphical model essentially graph that models dependencies between random variables graphical models intersection probability theory computer science that they graphs model distributions over random variables graphs highly efficient data structures storing information related dependencies thus they extremely useful case modeling distributions instance consider random variables then order represent distribution table format would require variables which intractable represent explicitly computer contrast graphical models with certain assumptions keep problem tractable conditional independence revisited three subsets vertices that this factorization forumulation equivalent conditional formulation states that state marginal independence facts about conditional independence repeat variables allowed repeat variables conditional statement convenience example fine actually equivalent second left does anything this will useful when writing generic theorems about conditional statements from graphical model avoid excluding repition cases decomposition implies both decomposes conditional independence statements directed graphical models definition with directed graphical model associated with also known bayesian network family distributions lecture october fall over defined follows distribution over legal factors definition above legal factors functions thus like conditional probability table could used define conditional distribution given values parents notes recall that parents node definition above factors have unique rule possibility that same distribution could have expansions with different factors turns that actually prove that factors unique will when show that below thus factors uniquely specified distribution terminology write where legal factors determined from then that factorizes according denote this also member will also sometimes write want make which variables considered distribution explicit notation proofs below give example three nodes graph from figure then this graph only there exists some legal factors leaf plucking property first show fundamental property which used proofs proposition leaf plucking property leaf parent anything suppose then then proof there definition lecture october fall this property show important fact that factors same conditional probabilities defined from joint thus factors correct conditionals proposition then proof prove this induction cardinality since there exists leaf node with children without loss generality assume that leaf labeled then just relabel nodes that true first notice step justified fact that leaf thus never appears step also justified same kind reasoning since leaf cannot appear explaining only function from this result induction reasoning noticing that still conclude this proof simply need show that indeed this property will automatically propagates induction have noticing that function only derive hence give equivalent definition notion factorization lecture october fall definition equivalent definition distributions that factorizes according denoted didn start with above definition reason that without proof above would know whether definition makes sense this definition circular indeed conditional defined from joint allowed normally define joint multiplying conditionals might distribution that satisfies this property remark adding edges more distributions with subset then subset examples trivial graphs example trivial graph with empty edge assume there edges then this graph contains only fully independent distributions this smallest complete digraph assume have complete graph thus with edges need acyclic have called chain rule which always true thus distributions belongs complete graph this biggest graphs with three nodes give insight different possible behaviors graph thoroughly enumerating possibilities node graph first options empty graph leading independence complete graph that gives further information than chain rule markov chain markov chain certain type showed this configuration show that have have that future conditionally independent past given present assuming arrow would represent time other there lecture october fall some distributions which marginally independent dependence flows through show conditional independence statement have figure markov chain latent cause type given show that indeed figure latent cause explaining away represented show this type graph basically stems from other hand general have that conditionally independent given unlike both latent cause model markov chain here marginally independent observing induces some dependence between lecture october fall figure explaining away structure from this graphical model called motononic property conditioning example abducted alien watch broken late structure explains this situation there competing explanation late might have been abducted aliens watch could broken notice time this example meaningful distribution could yield that alien tiny then alien late alien because knowing that late give some evidence that perhaps have been adbucted alien alien late broken watch alien late because that know that watch broken gets unlikely again that have been abducted alien more likely that late because watch thus conditioning more things increase decrease probability event hence word monotone remark cause advised since observational statistics provide with correlations causality notion note also that explaining away graph general true lastly important remember that every relationship expressed terms graphical models counter example take function where three random variables pairwise independent mutually independent conditional independence statements dgms definition path from then said nondescendent proposition then proof will only prove forward implication assume topological order then because chain rule always true lecture october fall chose topological order have show induction that this directly implies that idea notice that there exist topological order such that separation want answer queries such given three subsets true answer those issues need separation notion directed separation indeed easy that notion separation enough directed graph needs generalized definition chain from sequence nodes such that notice that chain hence path symmetrized graph graph where relation true then true well assume that observed want define notion being blocked this order answer underlying question above figure separation definition separation chain from blocked node given either structure lecture october fall structure descendants chain from considered blocked blocked some node along said separated only chains that from blocked rules above example markov chain prove that future independent past given present with markov theory might difficult separation notion gives results directly figure markov chain hidden markov model often used because only observe noisy observation random process observationsetats figure hidden markov model proposition conditional independence statements such that separated bayes ball algorithm this intuitive reacheability algorithm determine conditional independence statements seperation suppose want determine conditionally independent from given place ball each nodes them bounce around according some rules described below reaches true none reached otherwise balls implement path rules from separation blocked accordingly rules follows three canonical graph structures note that balls allowed travel either direction along edges graph lecture october fall figure markov chain rule when observed balls blocked left when observed balls pass through right markov chain balls pass through when observe blocked otherwise children balls pass through when observe blocked otherwise figure rule when children when observed balls blocked left when observed balls pass through right structure balls pass through when observe blocked otherwise figure structure rule when observed balls blocked left when observed balls pass through right properties inclusion reversal marginalization inclusion property here quite intuitive proposition about included graphs their factorization lecture october fall proposition then proof have obvious that therefore going back definition graphical models through potential result reversal property also have some reversal properties first define notion structure definition there structure figure more parents proposition markov equivalence andif then reversed factorizes then factorizes with terms nodes graph this property ensures that markov chain latent cause equivalent also applying reversal property multiplle times conclude that directed trees built from undirected tree give same other hand structure lead different class graph compared others definition edge said covered figure edge covered reversing might might break acyclic property have following result proposition graph covered edge with then marginalization underlying question know whether marginalization distributions yield another show that marginalizing leaf node yield smaller graph marginalizing internal nodes might yield distributions which representable 
 probabilistic graphical models fall lecture october lecturer simon lacoste julien scribe philippe beardsell based scribe notes from jaime roquero jieying proofread quickly corrected simon lacoste julien general themes this class modeling high dimensional distributions representation represent family distributions examples convenient families given graphical models parametrization parameterize members family distributions example this that will using exponential family there many others inference compute where query evidence lecture elimination algorithm lecture product algorithm belief propagation statistical estimation estimate model from observations examples principles that maximum likelihood estimators maximum entropy method moments undirected graphical models markov random fields markov networks undirected graph cliques where clique fully connected nodes examples nodes which cliques from size lecture october fall associated with some potentials where normalizing constant partition function functions potential functions probability distributions unlike where could think node parents which implies potential directly related probability distribution remark multiply constant without changing because will normalize with therefore some undirected graph there multiple ways define probability example consider following graph could write could also write note that second equation rewrite simpler potential function form clique nodes potential function encompasses information about dependencies between nodes there loss generality making that transformation therefore sufficient consider only cmax maximal cliques where maximal clique clique that cannot extended including additional vertex restrict ourselves that case given that cliques subsets more maximal cliques then redefine note will later that sometimes convenient consider over parametrization trees using both property before lecture october fall trivial graphs consider with this gives that fully factorized that mutually independent consider with clique reduced single make conditional independence assumptions between distribution property then that exponential family negative energy function example ising model physics node potentials edge potentials another example could social network modeling lecture october fall conditional independence directed graphical models view undirected graphical models encoding independence assumptions their structure definition that satisfies global markov property with respect undirected graph only disjoint separates from then have figure separates from paths from must pass through proposition satisfies global markov property proof without loss generality assume consider case where then separated definition have disjoint union show that separated contradiction suppose there which separated there exists path from passing through then definition would contradicting definition cannot same time also have that original separated from thus have separated show that then decomposition property this implies subsets giving required general case thus continue proof with lecture october fall cannot have clique intersect both same time otherwise part would connected direct edges from this clique thus similarly thus this proves converse above theorem always true assignment assume that probability strictly positive holds given following deep theorem theorem hammersley clifford then satisfies global markov property proof chapter michael jordan book property closure with respect marginalization lecture october fall directed graphical models also have marginalization notion undirected graphs slightly different factorizes then factorizes graph where node removed neighbors connected edges connect neighbors together clique marginal definition markov blanket markov blanket node smallest nodes such that node conditionally independent other nodes given neighbors markov blanket node include parents children parents children children children table summarizes differences between moralization when transform undirected graph such that from same before answering this question first define undirected graph that lecture october fall table summary main differences between directed graphical model undirected graphical model factorization conditional independence separation many more separation marginalization closed general only when marginalizing leaf nodes closed cannot exactly capture some families grid structure definition call moralized graph where undirected graph with same vertices some undirected version moralization that moralization explained less formally connecting parents with clique note that only need edges when when there structure here examples this transformation note that conversion process from bayesian network markov random field loose marginal independence parents position answer original question when yields same note that terminology moralization come from fact that marrying parents adding edges between them thus from traditional christian point view making family moral lecture october fall proposition with structure forest then general only that note that minimal undirected graph such that proof this will done assignment proposition flipping covered edge that directed edge covered edge only suppose edge covered define with prove that proof note that order identify factors decomposition joint distribution provided with conditional distributions need show that indeed know that must prove that flipping introduce cycles recall that graph only topological order wlog assume that vertices original graph indexed with such topological ordering some sequence also topological ordering since then then topological ordering since everyone ancestors their left therefore thus have where denotes parents consider such that then chain rule valid distribution have covered edge have moreover definition have with parents note that equation interpreted simply swap terms product factorization lecture october fall then both above equal zero still equal thus have symmetry reverse argument thus 
 probabilistic graphical models fall lecture october lecturer simon lacoste julien scribe pravish sainath proofread quickly corrected simon lacoste julien inference motivation have seen about different types probabilistic graphical models their properties they model probability distributions encoding conditional independences find these graphical models answer specific questions about their distributions many situations want compute following probabilities from pgms marginal some conditional query nodes evidence nodes partition function normalization constant some situations that require inference determining missing data xunobserved xobserved example image infilling task computer vision prediction xfuture xpast example prediction next observation sequence time series identifying latent cause xcause xobservation example model quick medical reference diseases symptoms identify presence disease from observed symptoms related inference decoding maxxf example speech recognition identifying best sentence from speech data lecture october fall inference also needed sometimes when estimating parameters example when doing latent variable model need compute during step algorithm remark will present inference algorithms only ugms they simpler more general these applied dgms after converting them ugms using process moralization studied previous lecture joint probability distribution represented expressed equivalent follows moralization where idea graph eliminate algorithm main trick compute marginalization efficiently organize computation using distributivity property specific order this will yield graph eliminate inference algorithm that will describe soon distributivity property distributivity property reorganize probability expression distributivity over stated that functions have lecture october fall more generally suppose that each variables take values using this trick have transformed terms each including product values thus complexity product terms each which over terms thus complexity generalize this idea more complicated potentials graph elimination algorithm inference graph eliminate algorithm uses idea ditributivity successively eliminate variables summing over their values infer marginal probability query this called variable elimination graph eliminate algorithm present formal procedure graph eliminate algorithm compute marginal probability given query corresponding nodes from with cliques initialize choose elimination ordering such that nodes last nodes terms active list update repeat order variables eliminate pick variable eliminate from active list remove factors from active list that contains argument take their product product over variable factor where contains variables factors except clique over back active list call consistency notation lecture october fall normalize last factors left have only terms required probability proportional this needs normalized obtain final value illustrating example want compute probability distribution from whose graph given figure figure graph writing joint distribution factorized required probability expressed marginal joint probability summing over remaining variables splitting summation distributive property choose elimination ordering factors currently active list lecture october fall successively applying updates chosen order messages added active list removing factors containing eliminated variables probability distribution proportional message computed algorithm modifies original graph consecutively removing nodes passing messages other nodes that lead query node shown figure figure graph with computed messages lecture october fall properties graph eliminate algorithm memory cost suppose simplicity that each take values memory cost expressed terms number active variables each stage number factors active list maxi factors computational cost expressed terms number active variables each stage number nodes graph maxi augmented graph triangulated observed that cliques formed side effects while running algorithm running algorithm keeping track edges added between yields augmented graph that property being triangulated graph figure left triangulated graph right triangulated graph chord edge between neighboring nodes cycle definition triangulated graph graph with cycle size more that cannot broken chord other words cycle size broken chord triangulated graph illustrated figure during graph eliminate algorithm edges added turns that enough edges added ensure that resulting augmented graph triangulated example figure here black lines indicate original edges blue lines indicate edges introduced algorithm during elimination lecture october fall figure augmented graph after graph eliminate treewidth graph undirected graph treewidth defined treewidth size biggest clique over elimination orderings minus convention that treewidth tree treewidth tree both memory running time algorithm determined number variables largest elimination clique term size biggest clique algorithm tractable need achieve ordering giving minimum size largest clique which treewidth best ordering gives term treewidth complexities orderings good example removing central node node star graph gives large clique size leading very factor active list which computationally efficient seen figure whereas removing leaf nodes gives cliques size consistent with treewidth news about inference actually hard compute treewidth graph find best elimination ordering lecture october fall figure ordering star graph hard exact inference general thus instead need approximate inference methods general example treewidth grid graph with nodes actually growing with side grid shown figure later that ising models popular models computer vision they often have this grid structure later lectures will show approximate inference such using gibbs sampling variational method mean field these terms will defined later lectures figure grid graph with vertices good news about inference inference linear time graphs that trees treewidth product algorithm derived trees like hidden markov models markov chains efficient small treewidth graphs general graphs junction tree algorithm used 
 probabilistic graphical models fall lecture november lecturer simon lacoste julien scribe ismael martinez abdelrahman zayed disclaimer lightly proofread quickly corrected simon lacoste julien inference trees inference tree graph eliminate algorithm described last lecture using appropriate elimination ordering exemplified this corresponds marginalizing using distributivity trick good order perform graph elimination tree eliminate leaves first which makes sure that edges added augmented graph achieving treewidth maximal clique size figure applying graph elimination compute also apply graph elimination using root shown messages that passed from leaf nodes towards root computed according children factors containing active list where node child node lecture november fall figure using root node compute product algorithm trees product algorithm algorithm node edge marginals cheaply storing caching reusing messages using dynamic programming figure collect distribute phases compute marginal node arrows refer collect phase whereas green arrows refer distribute phase message from node node computed follows figure passing message from node node where neighbors lecture november fall using green arrows shown compute marginal node goal compute node only send messages neighbour when received messages from other neighbours message from node node computed according node marginal proportional factors left active list this message passing formulation proportional therefore edge marginal probability pair neighboring node node example computed follows figure computing marginal probability edge between node node want compute marginal pair nodes which adjacent then usually need more general graph eliminate algorithm example only works compute node marginals well edge marginals adjacent nodes could generalize argument made compute marginals more than nodes they connected taking product incoming messages boundary connected nodes well potentials connecting nodes lecture november fall figure example case where need graph elimination algorithm compute probability nodes green added edge appearing augmented graph when running graph eliminate there node ordering that choose with which would edges explaining product algorithm cannot used this example product schedule collect distribute schedule shown also flooding parallel schedule which works follows initialize messages uniform distribution every step parallel compute neighbour messages were correctly computed from previous step prove that tree diameter messages correctly computed fixed after steps they fixed points this update process product algorithm graphs with cycles loopy belief propagation whereas parallel iteratively computes messages tree loopy belief propagation provides general case approximate inference graphs with cycles loopy refers cycles initialise messages uniform distribution every step compute using convex combination domain between previous message calculation stabilize update where step size this approach known damping lecture november fall remarks this gives exact answer trees fixed point yields correct marginal tree algorithm doesn converge general right marginal sometimes loopy gives reasonable approximations getting conditionals used indicate fixed values conditioning keep variables fixed during marginalization each formal trick redefining potential function need worry about fixing variables redefine kronecker delta function otherwise computing stuff stuff result will give normalize over conditional lesson when graph eliminate over observed variables note product compute marginal product compute product algorithm main property used distributivity over require that semi ring need additive inverses product like algorithms other semi rings where replace operations same concepts second example above where product algorithm distributivity trick that mentioned previously motivate graph eliminate algorithm using this product semi ring takes form lecture november fall analogous where move from outside product inside move function from outside product inside message updates product algorithm become example example maxx maxx figure sequential message passing compute argmax store argument this function every product algorithm forward backtrack pointers full this algorithm decoding backtracking also known viterbi algorithm property tree tree with zero marginals then have proof idea similar define factors such that local consistency property holds then define joint show correct marginals lecture november fall figure store values forward pass backtrack pointers values this viterbi algorithm junction tree algorithm junction tree algorithm algorithm designed tackle problem inference general triangulated graphs generalization clique tree with junction tree property show clique tree with running intersection property then along path from tree that satisfies this property known junction tree build junction tree from triangulated graph maximum weight spanning tree clique graph where size separator sets weights edges clique graph other words spanning tree with maximum number nodes common among neighbouring cliques this tree will have running intersection property therefore junction tree theorem junction tree graph triangulated graph decomposable graph always turn graph into triangulated graph running graph eliminate algorithm once have junction tree show lecture november fall triangulated graph representation clique tree representation figure clique tree that follows running intersection property known junction tree junction tree shown here with dotted edges dotted edges additional edges present clique graph where edge between every pair cliques with some node common build spanning tree which running intersection property running maximum weight spanning tree algorithm clique graph with weight edges that size separator where separator sets junction tree junction tree algorithm reconstruct above formulation starting with where initialization message passing junction tree update potentials repeat step until convergence will have correct marginals 
 probabilistic graphical models fall lecture october lecturer simon lacoste julien scribe samuel beland leblanc disclaimer lightly proofread quickly corrected simon lacoste julien hidden markov model hidden markov model generalization latent variable model such gaussian mixture model example with added time dependence latent variables figure latent variable model example figure latent variable model with added dependence latent variable discrete later gaussian kalman filter observed variable continous speech signal discrete sequence lecture october fall from theory following joint probability emission prob transition prob often emissision probabilities transition probabilities homogeneous they depend hence have that named transition matrix stochastic matrix column transition matrix seen probability distribution over inference tasks there multiple inference tasks interest when using general task compute probability sequence hidden state given observable output sequence there also some marginal probabilities that interesting prediction where next filtering where term filtering comes from interpretation that output provides noisy information about underlying signal noisy signals filtered based value smoothing where past order perform these inferences need take advantage conditional independence involved graphical model when conditioning latent variables conditioning make independent future independent past given present this thus gives following note that some textbooks normalized convention instead normalized column simon prefers column convention then updates matrix vector products message passing updates later lecture october fall where recursion that will define recusion will product algorithm here derive recursions compute probabilities didactic example product ugms also derive these recursions directly instead figure visual representation recursion instead computing filtering distribution will compute joint marginal using message passing here using notation indicate that observation fixed marginalization lecture october fall with with note that above first equation because have node potential then define which expressed using above derivations making recursion explicit this recursion forward recursion like collect phase product algorithm using root also express matrix vector product from definition just proposed that vector matrix vector then using hadamard product redefine recusion like this initialization recursion simply also observe that renormalize over filtering distribution from also evidence probability time complexity matrix vector products over states repeated times space complexity only need extra storage alpha recursion note that takes store whole matrix transition matrix this given problem extra storage lecture october fall recursion smoothing figure visual representation recursion smoothing probability need also consider information this where beta recursion needed joint marginal observations have from conditional independence property explained earlier expanding message equation expose actual recursion with following initialization finally from product algorithm obtain edge marginal this seen observe anything marginalizing leaves there just yields value leaf plucking property lecture october fall numerical stability trick problem with doing inference amount multiplication values which makes that easily this underflow there tricks that used order avoid this general store instead imax then following imax normalize messages recursion previously defined filtering distribution initially possible show that hence recursion define note here that general will have reasonable value underflow advantage requiring much extra computation using stored values exercise derive recursion lecture october fall maximum likelihood first some parametric model gaussian where transition matrix since parents want estimate parameters from sequences data where have latent variable model going step iteration then step time simply recursion with parameters time step trying optimize this going complete likelihood look each term individually will able maximize with respect after soft counts smoothing distribution soft counts smoothing edge marginal lecture october fall maximize with respect this will depend parametric model used them using soft count maximum likelihood similar used gaussians weighted empirical mean just described what called baum welch algorithm consisting forward backward using recursion product with finally find maxz must viterbi algorithm product seen earlier 
 probabilistic graphical models fall lecture november lecturer simon lacoste julien scribe tapopriya majumdar disclaimer lightly proofread quickly corrected simon lacoste julien information theory kullback leibler divergence discrete distributions divergence between defined motivation from density estimation estimation given distribution recall statistical decision theory setting standard maximal likelihood loss loss giving following statistical loss when true distribution action note that above called cross entropy best action then loss entropy which obviously best outputting correct distribution therefore excess loss this case divergence interpreted excess loss outputting instead true distribution lecture november fall motivation from coding theory fact that coding theory optimal length code proportional bits then expected length code where entropy measured bits then divergence interpreted excess cost terms length code distribution coding opposed optimal distribution examples example entropy bernoulli distribution bern then which largest when example entropy uniform distribution states uniform then turns that uniform distribution states with maximum entropy among distributions over states properties this shown using jensen equality strictly convex each argument symmetric when maximal likelihood minimization parametric family distributions empirical distribution corresponding samples then when using natural base entropy measured nats when using measured bits lecture november fall proof xlog constant maximum entropy principle here idea consider some subset distributions over according some data driven constraint subset principle pick which maximizes entropy argmaxq argminq mdkl uniform uniform constant more generally also consider generalized maximum entropy principle where minq some distribution that want favor instead uniform which used standard maximum entropy soon role this when talk about equivalence maximum entropy with maximum likelihood exponential family example from wainwright observe kangaroos left handed kangaroos drink labatt beer then many kangaroos both left handed drink labatt beer here entropy solution that independence standard through empirical moments feature functions represent various measurements want make data then define that distributions which their model moments match empirical moments then constraint becomes some scalar linear lecture november fall equality when represented vector over elements hence finding using maximal entropy uniform such that becomes convex optimization problem over lagrangian duality segue convex functions affine functions here these functions extended real valued functions then primal convex optimization problem minimizexf such that define where langrange multipliers will present saddle point interpretation lagrangian duality uses following trick feasible feasible equivalent problem constrained primal problem following unconstrained problem using fancy complicated function duality trick swap lagrangian dual problem infx that always concave both components lagrangian dual problem solve lecture november fall weak duality infx always true because always feasible then strong duality when have equality when primal optimization problem convex sufficient condition strong duality slater condition such that where nonlinear feasible chapter boyd book http stanford boyd cvxbook more details note that after solving dual problem obtaining usually reconstruct primal optimal variables when strong duality holds using conditions which necessary linear equations that hold primal dual optimal variables dual problem maximal entropy uniform distribution then primal form maximal entropy problem find lecture deriving maximum likelihood parameter multinouilli will ignore inequality constraints divergence essentially acting barrier function making sure that stays positive only form lagrangian with moment equality constraints separate lagrange multiplier equality constraint later that will treat differently thus introduce corresponding lagrangian dual function need minimize lagrangian with respect convex just need find zero gradient have this example constraint qualification condition there others lecture november fall that part exponential family distributions dual function plugging this value abused shorthand notation below denote even though necessarily normalized where therefore maximize with respect plugging back eliminating from dual problem ensure that normalized which treated differently corresponding objective remaining dual problem lecture november fall interpret this dual problem link with maximum likelihood exponential family then where then dual problem which same maximal likelihood estimate summarize maximal likelihood exponential family with sufficient statistics equivalent maximal entropy problem with moment constraints where they lagrangian dual another exponential family maximum entropy with moment constraints note moreover that generalized maximum entropy principle minq with instead uniform then exponential family with reference density instead uniform distribution remark model moment therefore where empirical moment note that maximal likelihood parameters exponential family also doing moment matching which expected equivalence above lecture november fall case exponential family have that maximum likelihood equivalent maximum entropy which equivalent moment matching other parametric families mixture models example which exponential family then moment matching could give different estimator than maximum likelihood 
information theory exponential families lecture october lecturer guillaume obozinski scribe thomas belhalfaoui chizat information theory entropy will following properties jensen inequality convex integrable random variable strictly convex have equality only constant definition entropy random variable taking values finite denote information theory quantity interpreted quantity information carried occurrence this sometimes called self information entropy defined expected amount information random variable base logarithm natural base latter being more consistent with coding interpretations entropy this course will natural logarithm kullback leibler divergence definition kullback leibler divergence finite distributions kullback leibler divergence between defined lecture october divergence distance symmetric proposition equality holds only proof there exists such that then otherwise without loss generality assume that everywhere make this assumption rest proof convexity function jensen inequality have since furthermore there equality jensen inequality above which implies that summing this last equality over implies that which turn implies that proposition have following inequalities with equality constant card proof since then which implies that with equality which proves first point then choose then card hence card card definition mutual information random variables joint distri bution with marginal distributions mutual information defined lecture october proposition proof directly follows from fact that implies that which definition independence independent correlated correlated independence first implication comes from fact that then then counter example reverse implication following uniform distribution define random variables then correlated dependent remark reverse only true gaussian random variables relation between minimum kullback leibler divergence maximum likelihood principle definition empirical distribution observations random variable empirical distribution derived from this sample where dirac function null everywhere except where takes value proposition parameterized distribution maximizing likelihood equivalent minimizing divergence pjjp proof pjjp second term equal opposite likelihood hence conclusion lecture october remark should compute because this would rule values that have encountered such that maximum entropy principle maximum entropy principle different principle than maximum likelihood principle solves different kind problem assumes that data specify constraint possible distribution choose idea maximize entropy under constraint that where possible distribution typically specified from data consider following examples study kangaroos estimated that kangaroos left handed drink foster beer what reasonable estimate fraction kangaroos that both left handed drink foster beer maximum entropy principle invoked choose among distributions pairs binary random variables particular formalize that want choose least specific distribution that satisfies these constraints find distribution with maximal entropy that satisfies constraints marginals variable left handed drinks foster beer then problem formalized what solution this problem exercise among distributions what distribution with expected value equal which largest entropy exercise possible show that distribution with fixed mean fixed variance that maximal differential entropy gaussian distribution principle maximum entropy also principle invoked construct distribution angles with fixed mean variance leads called wrapped normal distribution related distribution angle which also maximum entropy distribution mises distribution maximum entropy principle used often when working with contingency tables entropy divergence continuous random variables continuous random variable taking values continuous space probability density function have following adapted expressions entropy divergence lecture october differential entropy hdiff differential kullback leibler divergence ddiff continuous case entropy necessarily negative remark definition hdiff depends reference measure this means that hdiff does capture intrinsic properties more loses physical interpretation terms quantity information least absolute sense contrast ddiff does depend choice reference measure therefore stronger interpretation exponential families observations random variable definition statistic just function data definition sufficient statistic statistique exhaustive french function sufficient statistic model only note that order estimate from data using maximum likelihood principle information statistics carries information that relevant another interpreting what sufficient statistic take bayesian point view bayesian statistics parameter modelled random variable then have which means that definition exponential family random variable exponential family family distribution form where lecture october ancillary statistic reference measure base measure sufficient statistic also called feature vector parameter canonical parameter partition function proposition proof definition canonical exponential family canonical exponential family exponential family which such that definition domain domain exponential family defined example multinomial model random variable follows multinomial distribution parameter this expression easily recognize lecture october counting measure constant function equal recognize find using proposition that first expression likelihood exponential form take into account fact that there hidden constraint have expression more constraint over values that take example gaussian distribution over recognize exponential family with lecture october domain example many other common distributions exponential families binomial poisson dirichlet gamma exponential link with graphical models xixj figure ising model example ising model xixj ijij xixj this first expression overparametrized rewrite expression with just parameter pair ijxixj lecture october example general discrete graphical model general case discrete graphical model such that have where possible values clique recognize minimal representation remark actually does depend only definition common probability zero definition affinely dependent statistics denote sufficient statistics said affinely dependent definition minimal representation exponential family vector sufficient statistics provides minimal representation exponential family these statistics affinely independent theorem every exponential family admits least minimal representation necessarily unique unique minimal dimension remark will quite often redundant minimal representations lecture october exponential family sample consider sample distributed according which belongs exponential family then sufficient statistics where canonical parameter domain remain same single observation partition function general exponential family general exponential family parametrize with function such that open connected subset definition curved exponential family exponential family said curved jacobian full rank example convexity differentiability exponential families lemme lder inequality such that jjxj jjyj where jjxj jpdx jqdx theorem convexity canonical exponential family have following properties lecture october convex subset convex function convex function proof singleton result trivial there exist such that thus convex function moreover which proves that convex taking obtain hence convex function corollary canonical exponential family maximum likelihood estimator solution convex optimization problem proof likelihood concave lecture october remark theorem does hold those cases family curved fully observed consider marginal likelihood observations theorem then proof technical standard show using dominated convergence theorem that exchange differentiation expectation computations differentials then which proves first formula general deduced induction 
approximate inference sampling variational inference fall cours november enseignant guillaume obozinski scribe basile ment nathan lara approximate inference with mcmc gibbs sampling consider undirected graph associated distribution from which want sample order inference example assumed that difficult sample directly from easy sample from idea consists using markov property that jxni where markov blanket node based this gibbs sampling process that converges distribution most classical version gibbs sampling algorithm cyclic scan gibbs sampling algorithm cyclic scan gibbs sampling initialize while while return another version algorithm called random scan gibbs sampling consists picking index random each step cours november fall algorithm random scan gibbs sampling initialize while draw uniformly random while return application ising model consider ising model graph random variable which takes values with probability distribution that depends some parameter ijxixj apply gibbs sampling algorithm need compute xijx have ijxixj xjxj thus ijzxj xjxj taking ratio previous quantities last terms cancel xixj xijx particular xijx ijxj ijxj cours november fall where logistic function without surprise conditional distribution xijx only depends variables that neighbors graph that form markov blanket since must have xijx since conditional distribution given other variable bernoulli easy sample using uniform random variable proposition random scan gibbs sampling satisfies detailed balance gibbs distribution interest distribution graphical model proof consider step random scan gibbs sampling algorithm starting from distribution graphical model idea prove reversibility first prove result index fixed that prove that transition gibbs that only resamples coordinate reversible write xijx conditional distribution xijx gibbs distribution using kronecker symbol defined else have gibbs xijx gibbs detailed balance gibbs valid random scan case index being chosen random uniformly with probability gibbs transition fact gibbs result then obtained taking average over previous derivation thus stationary distribution random scan gibbs transition proposition gibbs transition random cycle regular then defined gibbs sampling algorithm converges distribution gibbs distribution exercise extend gibbs method potts model exercise prove that gibbs transition special case metropolis hastings proposal that always accepted cours november fall variational inference overview goal approximate inference without using sampling indeed algorithms such metropolis hastings gibbs sampling very slow converge besides practice very difficult find good stopping criterion people working mcmc methods find clever tricks speed process hence motivation variational methods consider distribution finite usually very large exponential family with assume that distribution interest that example distribution graphical model that working with goal compute computing this expectation corresponds probabilistic inference general example potts model using notation have xikxjl recall that argmin qjjp where qjjp since associated with parameter where moment parameter course exponential families thus have pjjq this quantity always negative thus maximizing with respect exponential family leads unique value that attains maximum remark possible here express things only terms moment indeed parameterize distribution realizable exponential family there single distribution maximization problem becomes cours november fall where where called marginal polytope possible moments maximum only attained which exactly expectation that needs computed turns that possible show that always concave function that optimization problem above convex optimization problem interesting note that have thus turned probabilistic inference problem which priori required compute expectations that integrals into optimization problem which furthermore convex unfortunately this convex optimization problem hard solve general because solves hard probabilistic inference problem possible escape fact that latter hard this optimization problem thus general intractable this because reasons general graph marginal polytope number faces which exponential tree width graph function extremely complicated write explicitly mean field order approximate optimization problem possible either change distribution moments change definition entropy mean field technique consists choosing that makes variables independent graphical models variables consider collection distributions that make variables independents consider optimization problem which replace note that general that solution cannot exactly order write this optimization problem potts model need write explicitly have seen course exponential families that distribution maximum entropy under moment constraint also when exists distribution maximum likelihood exponential family associated with sufficient statistic this essentially exactly shows that moment there exists member exponential family such that fact rigorous careful about what happens points boundary correct statement that every interior there exists distribution exponential family such that points boundary only corresponding limits distributions exponential family that degenerate like bernoulli distribution with probability example bernoulli family case which themselves family cours november fall moments mean field formulation ijkl xikxji have other hand independence variables lead xikxjl note that constrained make these variables independent would general have moment here form xikxjl ijkl this main place where mean field approximation departs from exact variational formulation entropy mean field formulation independence variables recall that distribution single node that multinomial random variable mean field formulation potts model putting everything together optimization problem written ijkl problem simple express however cannot longer expect that will solve original problem because restricting have restrained forms that moment parameters ijkl xikxjl take particular since general optimal solution mean field formulation does retrieve correct moment parameter approximation will reasonable from sets moments that achievable moments distributions since moments approximated moments closest independent distribution note cours november fall however that mean field approximation much more subtle than ignoring binary potentials model which would naive finding approximation with independent distribution difficulty though that objective function longer concave because products which arise because independence assumption from mean field approximation coordinate descent each algorithm choice solve this kind problem present algorithm consider case ising model which special case potts model with states each variable mean field formulation ising model when working with ising model simple reduce number variables using fact that therefore write mean field optimization problem becomes stationary points each coordinate correspond zeros partial derivatives that where logistic function note that gibbs sampling with probability ijxj this called mean field because sampling replaced approximation where assumed that sample value equal expectation which physicist correspond mean field ferromagnetic ising model finally lets insist that mean field formulation only formulations variational inference there several other ones among which structured mean field expectation propagation loopy belief propagation which reinterpreted solving variational formulation well tree reweighted variational inference 
introduction probabilistic graphical models lecture december lecturer simon lacoste julien scribes gauthier gidel lilian besson note these scribed notes have only been lightly proofread bayesian method introduction vocabulary priori prior likelihood marginal likelihood posteriori posterior caricature bayesian frequentist bayesian optimistic thinks that come with good models obtain method pulling bayesian crank basically high dimensional integral frequentist more pessimistic uses analysis tools bayesian formulation enables introduce priori information process estimation instance imagine that play heads tails bayesian model graphical model associated represented figure figure graphical model biased coin game cours december compute posterior then beta where number question what probability head next frequensist maximum likelihood approach bayesian where posterior distribution then hence prior convex combination prior then notice that quantity whereas underlines importance prior distibution with unknown coin information priori uniform with normal coin distribution with important concentration mass around bayesian ering limited estimator maximum likelihood estimator which gives unique value enough because estimator itself translate inherent uncertainty learning process thus estimator will density posteriori obtained from bayes rule which written continuous notations bayesian speci uncertainty with distributions that form estimator rather than combining estimator with dence intervals bayesian forced produce limited estimator uses expectation underlying quantity under posteriori distribution instance post cours december more details about bayesians subsection annex then need show that variance variance beta then posterior covariance vanishes where true parameter model bernstein mises theorem says that prior puts zero mass around true model then posterior asymptotically concentrate around gaussian revisiting example consider repeating several times experiment above coins picked randomly each ipped times figure figure graphical model biased coin game repeated times frequentist empirical distribution will converge where distribution coins parameter mixture distribution note that independent other hand cours december exchangeable situations exchangeablility random variables exchangeable they have same distribution permutation indices nite exchangeablility nition naturally generalizes nite families indexed random variables exchangeable every nite subfamily exchangeable finetti theorem nitely exchangeable only some space such that care about exchangeable situations variables particular case situation exchangeable variables that practice however when data combined with scalar observations erent components longer independent some cases those components nonetheless exchangeable instance text words shown sequences that exchangeable because syntax forget order words word model then components exchangeable basic principle used model multinomial example mult where that distribution have hence there exists such that that case this frequentist model over bayesian model puts prior which convenient property prior families conjugacy introduced below cours december conjugacy consider family distribution says that conjugate family observation model posterior belongs same family than prior multinomial distribution gives then dirichlet distribution dirichlet distribution conjugate multinomial wikip more details where stands uniform measure simplex then gets uniform distribution gets beta distribution there exists such that gets shape distribution gets unimodal bump cours december multinomial model assume that prior then posterior posterior mean instance with adds smoothing maximum likelihood estimator consider that posterior used prior next observation this sequential approach cours december bayesian linear regression assume that where then observation issue then also choose gaussian prior then posterior also gaussian with following parameters covariance mean where covariance mean same ones ridge regression with bayesian compute predictive distribution jxnew jdata ynewj xnew predictive where predictive xnew nxnew real number comes from noise model second quantity right hand side comes from posterior covariance ynew ynew jxnew cours december model selection introduction consider models with where figure exampleofmodelsectionforn onthel sandm onther maximum likelihood score since have nition interested capacity generalisation model like avoid over tting commonly dealing with that task select size model cross validation here develop furthermore this part present bayes factors which gives main bayes principal selecting models also will show link with penalised version bayesian information criterion which used frequentists correct maximum likelihood which good proprieties issue with selection model issue with selection variables which active topic research there others ways penalising maximum likelihood selecting models distribution real data wish choose between erence models maximising where test sample distributed fact still maximum likelihood principle take expectation data bayesian framework compute marginal probability data given model djmi cours december applying bayes rule compute posteriori probability model djmi mijd bayes factor introduce bayes factors which enables compare models marginal probability data djmi xnjmi decompose itself sequential using xnjx indeed xnjx such djmi xijx bayesian information criterion bayesian score approximated with data distribution when parameter maximum likelihood estimator number parameters model number observations following section outline proof this result case exponential family given cours december laplace method where negligible rest maximum likelihood dual maximum entropy such that however information sher equal thus main reason presenting that theorem prove consistency other words when number observations cient thanks this criterion choose with probability that converges model that satis argmaxm cours december bring quick clari cation about notations used this part model selection please read below notation confusing used example bishop book sloppy from bayesian perspective could treat model choice random variable example there only models thus discrete variable with possible values therefore when were writing quantities like bayes factor really meant mean that were erent random variables which take complicated values someone asked what space seemed very complicated what meant just that index possible models data random variable usual mixing random variables here their possible values same notation like usual confusing better explicit notation distinguish value generic random variable however general could complicated want example could vector hyper parameters prior distributions could also have binary component indicating absence presence edge graphical model does have just index could even continuous objects also have nite dimensional objects example consider latent variable model observed latent variables decides prior over suppose multi ranges over possible distributions over positive vector here quite complicated object this this would parametric setting parametric nite dimensional appendix example model bernoulli variable consider random variables assume that conditionally then they follow bernoulli priors introduce distribution beta whose density where short name beta function gamma function show that symmetric satis choose prior distribution beta distribution cours december posteriori hence thus instead considering unique variable observe sample data joint distribution written introduce then special case beta distribution remind that beta uniform prior bell curve curve cours december mode case write data post that posteriori expectation parameter convex combination maximum likelihood estimator prior expectation converges asymptotically maximum likelihood estimator uniform prior distribution laplace proposed correct frequentist estimator seemed that absence data proposed virtual observation such that absence data estimator equals this correction known laplace correction variance posteriori distribution decrease have chosen sharper distribution around same than frequentist approach dence intervals narrow around estimator when number observations increase playful propriety this well known property gamma function such that write simplify expression cours december shall note analogy with polya model consider balls colour black white when drawing black ball probability event after drawing back ball ball same colour imagine that draw again black ball then probability this event however more general case show recurrence that marginal probability obtaining some sequence colours drawing from polya exactly marginal probability obtaining same result from marginal model obtained integrating priori theta first this show that drawings from polya exchangeable secondly mechanism this type exchangeability useful gibbs sampling same type bayesian models conjugate priors assume that known deduce from that such that that conjugated model exponential model consider canonical parameter canonical parameter cient statistic note that stand beta distribution then cours december since family exponential post results from thus previous equation consequently univariate gaussian with priori thus cours december where thus post post indeed variance decreases with priori inverse gamma form with priori gaussian priori inverse gamma priori please refer chapter course handout jordan polycopi appendix posteriori maximum because with bayes rule posteriori maximum really bayesian rather slight modi cation brought frequentist estimator predictive probability bayesian paradigm probability future observation will estimated predictive probability cours december sequential calculus possible since xnjx vocabulary priori information likelihood posteriori information naive bayes introduction remarque contrary name naive bayes bayesian method consider following problem classi cation here vector descriptors features with goal learn very naive method will trigger combinatorial explosion bayes formula gets naive bayes method consists assuming that features conditionally independent from class hence xijy then bayes formula gives xijy xijy xijy cours december consider case where features take discrete values consequently graphical model contains only discrete random variables then write discrete model exponential family indeed write that dummy functions cient statistics joint distribution model variables where canonical parameters thus write where partition function have rewritten joint distribution model exponential family given that maximum likelihood estimator exponential family where canonical parameters combined also maximum entropy estimator seen previous course provided that statistical moments cient statistics equal their empirical moments thus introduce nikk nikk maximum likelihood estimator must satisfy moment constraints nikk nikk nnik which them completely then write estimators canonical parameters however goal obtain classi cation model that model only conditional probability from approximated generative model applying bayes rule cours december xijy xijy write conditional model exponential family cient statistics canonical parameters equal those generative model seen functions random variable given that could write partition function equal warning maximum likelihood estimator generative model which usually equal maximum likelihood estimator conditional model advantages drawbacks advantages doable line computationally tractable solution drawbacks generative generative models produce good estimator whenever model true statistical words well speci which means that process that generate real data induce distribution equal generative model when model well speci which most common case better discriminative method discriminative method problem that have considered previous section generative model classi cation classes learn discriminatory classi classes possible exponential family have already seen logistic regression classes classi cation study multiclass logistic regression cours december although have built model from erent staring consideration resulting modelling that possible distribution same exponential family than naive bayes model nonetheless tted model discriminatory approach will erent from tted generative approach tting multiclass logistic regression results from maximisation likelihood classes learning given that other words tting obtained computing maximum likelihood estimator conditional model unlike what happens generative model estimator obtained analytical form learning requires solving numerical optimisation problem 
